{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b420ff70-a705-412b-9309-629a51f2c4f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Free System Memory and begin all imports \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2> Free System Memory and begin all imports <h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a138b-e092-44d7-99ce-abe519c3a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Check free memory available\n",
    "%system free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9269303-433a-4c90-b307-5ff3f429e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas_gbq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244117e-d20c-40e3-a26a-f198b91cc3e6",
   "metadata": {},
   "source": [
    "\n",
    "![Screenshot 2024-01-02 at 09.53.29.png]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d19c4-5b83-4be9-bbe4-22fa5753790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from google.cloud import bigquery\n",
    "import gc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas_gbq as pdg\n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57bebc-e8dc-413a-a7d5-fa19a3ed3c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retrieving records from EYFSP table\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2> Retrieving records from EYFSP table to calculate the GLD for early years of the records which uses different framework to ascertain Good Level of Development. Each of the 13 ELA the student should have scored 6 and above and the Total EYFSP should be greater than or equal to 78</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979ea0f-fd76-4c3d-9abd-9ac262e2bef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instaniate BigQuery client\n",
    "\n",
    "sqlEY = \"\"\" SELECT person_id,AcademicYear,Gender,PSEAS1,PSEAS2,PSEAS3,PSETotal,\n",
    "    CLLAS1,CLLAS2,CLLAS3,CLLAS4,CLLTotal,\n",
    "    PSRNAS1,PSRNAS2,PSRNAS3,PSRNTotal,\n",
    "    RKUW,RIPD,RICD,EYFSPTotal,\n",
    "    COMG01,COMG02,COMG03,PHYG04,PHYG05,PSEG06,PSEG07,PSEG08,\n",
    "    LITG09,LITG10,MATG11, MATG12,UTWG13,UTWG14,UTWG15,EXPG16,EXPG17,GLD  FROM `yhcr-prd-phm-bia-core.CB_FDM_DepartmentForEducation.src_EYFSP` a \"\"\"\n",
    "\n",
    "EarlyYears = pdg.read_gbq(sqlEY, dialect='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0341a-b3c3-4162-b9ef-9b8ed211f834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = EarlyYears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9601ab-e7f9-4975-9e2a-fbcc821754e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a51f0-de1c-4b0e-bd90-8feb2f6d24ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.person_id.nunique()\n",
    "# there are 130551 unique records in EYFS table\n",
    "# 89 records as duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2d772-bc1e-45e4-9156-6b0f087a1c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['person_id'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160a477-90e2-45a3-a7b6-e4d9c6d5006a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b6ac8-f2ae-4cf0-b843-52e971390510",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gender aggregation\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2> \n",
    "Gender - change all cases of female, f, F or Female to F -  'F' and 'f' as 'F' - Female\n",
    "All 'M' and 'm' as 'M' - Male\n",
    "</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe3169-52de-4507-adae-e34bce658282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['newGLD'] = df['GLD'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "# df['Gender'] = df['Gender'].apply(lambda set_: 'F' if (set_== 'f') else set_ )\n",
    "# df['Gender'] = df['Gender'].apply(lambda set_: 'M' if (set_== 'm') else set_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae0a96-65f5-41f0-8bd8-f71f08218d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['newGLD'] = df['GLD'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "df['Gender'] = df['Gender'].apply(lambda set_: 'F' if (set_== 'f') else set_ )\n",
    "df['Gender'] = df['Gender'].apply(lambda set_: 'M' if (set_== 'm') else set_)\n",
    "df[\"AcademicBegin\"]  = df[\"AcademicYear\"].str.slice(0, 4)\n",
    "df[\"AcademicEnd\"] = df[\"AcademicYear\"].str.slice(5)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc4f27-e724-49c1-a814-feaec3b51b4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Changing the Data types of the Scores of the subjects to be numeric from string \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2> Changing all scores datatype to integer for calculations purposes from string and handling None\n",
    "</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0451c0-5e1b-4d35-b97e-35bc9d17b4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df['PSEAS1'] = df['PSEAS1'].apply(lambda set_: 0 if np.nan(set_)== True else int(set_))\n",
    "\n",
    "df['PSEAS1'] = df['PSEAS1'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['PSEAS2'] = df['PSEAS2'].replace({None: 0,'N': 0}).astype(int)   \n",
    "df['PSEAS3'] = df['PSEAS3'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['PSETotal'] = df['PSETotal'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['CLLAS1'] = df['CLLAS1'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['CLLAS2'] = df['CLLAS2'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['CLLAS3'] = df['CLLAS3'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['CLLAS4'] = df['CLLAS4'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['CLLTotal'] = df['CLLTotal'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['PSRNAS1'] = df['PSRNAS1'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['PSRNAS2'] = df['PSRNAS2'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['PSRNAS3'] = df['PSRNAS3'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['PSRNTotal'] = df['PSRNTotal'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['RKUW'] = df['RKUW'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['RIPD'] = df['RIPD'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['RICD'] = df['RICD'].replace({None: 0,'N': 0}).astype(int)  \n",
    "df['EYFSPTotal'] = df['EYFSPTotal'].replace({None: 0,'N': 0}).astype(int)  \n",
    "\n",
    "df['AcademicBegin'] = df['AcademicBegin'].astype(int)\n",
    "df['AcademicEnd'] = df['AcademicEnd'].astype(int)\n",
    "\n",
    "#df.dtypes\n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e521d06-4d3e-48c0-ac03-c310f755e6d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set GLD flag to True if the student has scored 6 or more in all domains\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3> For records pertaining to early years from 2002 - 2012 we have to set the GLD flag based on computation <br/>\n",
    "         1. GLD Flag set it to true if all individual learning goals is above or equal to 6 and <br/>\n",
    "         2. if the Total is greater than or equal to 78. Otherwise the GLD flag is set to false <br/>\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe5a13-a4ee-46a4-aa74-af3ce44a5b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.loc[(df['PSEAS1']>=6)&(df['PSEAS2']>=6)&(df['PSEAS3']>=6)&\n",
    "#        (df['CLLAS1']>=6)&(df['CLLAS2']>=6)&(df['CLLAS3']>=6)&(df['CLLAS4']>=6)&\n",
    "#        (df['PSRNAS1']>=6)&(df['PSRNAS2']>=6)&(df['PSRNAS3']>=6)&\n",
    "#        (df['RKUW']>=6)&(df['RICD']>=6)&(df['RIPD']>=6)&(df['EYFSPTotal']>=78), 'newGLD'] = True   \n",
    "\n",
    "\n",
    "df = df.assign(newGLD=(df['PSEAS1']>=6)&(df['PSEAS2']>=6)&(df['PSEAS3']>=6)&\n",
    "       (df['CLLAS1']>=6)&(df['CLLAS2']>=6)&(df['CLLAS3']>=6)&(df['CLLAS4']>=6)&\n",
    "       (df['PSRNAS1']>=6)&(df['PSRNAS2']>=6)&(df['PSRNAS3']>=6)&\n",
    "       (df['RKUW']>=6)&(df['RICD']>=6)&(df['RIPD']>=6)&(df['EYFSPTotal']>=78))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b226cd-bc8b-4ffe-b35c-8f06fcc754ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.loc[(df['PSEAS1']>=6)&(df['PSEAS2']>=6)&(df['PSEAS3']>=6)&\n",
    "#        (df['CLLAS1']>=6)&(df['CLLAS2']>=6)&(df['CLLAS3']>=6)&(df['CLLAS4']>=6)&\n",
    "#        (df['PSRNAS1']>=6)&(df['PSRNAS2']>=6)&(df['PSRNAS3']>=6)&\n",
    "#        (df['RKUW']>=6)&(df['RICD']>=6)&(df['RIPD']>=6)&(df['EYFSPTotal']>=78)&(df['newGLD']== False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ef95f-e673-4740-ace8-a4d39c155b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c295e0-177d-4da5-ae96-f492cf4c484c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip  install hvplot\n",
    "#! pip  install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be34aa-6937-4be4-b18c-b7e96467bbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas  # noqa\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9bbb9c-97ed-478a-8714-b212d2d8b4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = rf.drop(['GLD'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b16193-9ff8-4716-a812-2568c6523080",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Stats to find out how many students have passed year on year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6553a2-9a25-4cee-a25e-c5e49642207a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EYGP = rf.groupby(['AcademicBegin','Gender', 'newGLD']).agg({\n",
    "                    'Gender':'value_counts'\n",
    "}).rename(columns={'Gender':'COUNTByGender'})\n",
    "#EYGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e72c03-85b1-45b3-86b6-054a99d55dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = EYGP.reset_index()\n",
    "GLDTrueFGenderData = matrix[(matrix['newGLD']==True) & (matrix['Gender']=='F') ]\n",
    "GLDTrueMGenderData = matrix[(matrix['newGLD']==True) & (matrix['Gender']=='M') ]\n",
    "\n",
    "GLDFalseFGenderData = matrix[(matrix['newGLD']==False) & (matrix['Gender']=='F') ]\n",
    "GLDFalseMGenderData = matrix[(matrix['newGLD']==False) & (matrix['Gender']=='M') ]\n",
    "\n",
    "GLDTrueFGenderData = GLDTrueFGenderData.drop(['Gender','newGLD'], axis=1)\n",
    "GLDTrueMGenderData = GLDTrueMGenderData.drop(['Gender','newGLD'], axis=1)\n",
    "\n",
    "GLDFalseFGenderData = GLDFalseFGenderData.drop(['Gender','newGLD'], axis=1)\n",
    "GLDFalseMGenderData = GLDFalseMGenderData.drop(['Gender','newGLD'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c85d4-eccc-4700-a84e-fc2bd37d896c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "# plt.bar(X_axis - 0.2, GLDTrueFGenderData, 0.4, color=\"purple\",label = 'Women Passed GLD')\n",
    "# plt.bar(X_axis + 0.2, GLDTrueMGenderData, 0.4, color=\"red\", label = 'Men Passed GLD')\n",
    "  \n",
    "ax = GLDTrueFGenderData.set_index('AcademicBegin').plot.bar(color=\"red\")\n",
    "bx = GLDTrueMGenderData.set_index('AcademicBegin').plot.bar(color=\"lightblue\")\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Count of Women who passed GLD\")\n",
    "bx.set_ylabel(\"Count of Men who passed GLD\")\n",
    "\n",
    "#plt.xticks(X_axis, X_Label)\n",
    "plt.legend()\n",
    "plt.xticks(rotation = 90, fontsize = 10)\n",
    "plt.xlabel(\"Academic Years\")\n",
    "\n",
    "plt.title(\"GLD Attainment\")\n",
    "\n",
    "\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    ax.set_title(\"Count of Women who passed GLD\")    \n",
    "    \n",
    "for bar in bx.patches:\n",
    "    height = bar.get_height()\n",
    "    bx.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    bx.set_title(\"Count of Men who passed GLD\")    \n",
    "\n",
    "plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358a5f1-4196-497c-8553-fd7736d1304d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import ticker\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # plt.bar(X_axis - 0.2, GLDTrueFGenderData, 0.4, color=\"purple\",label = 'Women Passed GLD')\n",
    "# # plt.bar(X_axis + 0.2, GLDTrueMGenderData, 0.4, color=\"red\", label = 'Men Passed GLD')\n",
    " \n",
    "# plt.figure(figsize=(50,50))\n",
    "\n",
    "\n",
    "# ax = GLDFalseFGenderData.set_index('AcademicBegin').plot.bar(color=\"lightpink\")\n",
    "# bx = GLDFalseMGenderData.set_index('AcademicBegin').plot.bar(color=\"yellow\")\n",
    "\n",
    "\n",
    "# ax.set_ylabel(\"Count Female Students Not Attaining GLD\")\n",
    "# bx.set_ylabel(\"Count Male Students Not Attaining GLD\")\n",
    "# ax.set_xlabel(\"Academic Years\")\n",
    "# bx.set_xlabel(\"Academic Years\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xticks(rotation = 90, fontsize = 10)\n",
    "\n",
    "\n",
    "# plt.title(\"GLD Attainment\")\n",
    "\n",
    "\n",
    "# for bar in ax.patches:\n",
    "#     height = bar.get_height()\n",
    "#     ax.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "#             ha='center')\n",
    "#     ax.set_title(\"Count Female Students Not Attaining GLD\")    \n",
    "    \n",
    "# for bar in bx.patches:\n",
    "#     height = bar.get_height()\n",
    "#     bx.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "#             ha='center')\n",
    "#     bx.set_title(\"Count Male Students Not Attaining GLD\")    \n",
    "\n",
    "# plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2224a-ad2f-4788-bdfe-0278655b9b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDFalseFGenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634802a-4912-4a9e-aa57-39076b02d54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDFalseMGenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be0c63-dcc2-4928-92a5-24b31ca7e850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "# Create subplots to avoid overlapping bars\n",
    "ax = plt.subplot(1, 2, 1)  # First subplot for female data\n",
    "\n",
    "# Plot the bars for female and male data on separate subplots\n",
    "ax = GLDFalseFGenderData.set_index('AcademicBegin')['COUNTByGender'].plot.bar(ax=ax, color=\"lightpink\", label='Women Not Attaining GLD')\n",
    "# Set labels and title for each subplot\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Academic Years\")\n",
    "ax.set_title(\"Female Students Not Attaining GLD\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "\n",
    "# Add title for the entire plot (optional)\n",
    "plt.suptitle(\"GLD Attainment by Gender\")\n",
    "\n",
    "\n",
    "# Add annotations (text labels) on top of each bar\n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in the bar plots.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, height + 1, f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "\n",
    "autolabel(ax.patches, ax)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing to prevent overlapping elements\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b9d71-de72-47cd-907f-dc4d90af92ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "# Create subplots to avoid overlapping bars\n",
    "bx = plt.subplot(1, 2, 1)  # First subplot for female data\n",
    "bx = GLDFalseMGenderData.set_index('AcademicBegin')['COUNTByGender'].plot.bar(ax=bx, color=\"yellow\", label='Men Not Attaining GLD')\n",
    "\n",
    "bx.set_ylabel(\"Count\")\n",
    "bx.set_xlabel(\"Academic Years\")\n",
    "bx.set_title(\"Male Students Not Attaining GLD\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "\n",
    "# Add title for the entire plot (optional)\n",
    "plt.suptitle(\"GLD Attainment by Gender\")\n",
    "\n",
    "\n",
    "# Add annotations (text labels) on top of each bar\n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in the bar plots.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, height + 1, f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "\n",
    "autolabel(bx.patches, bx)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing to prevent overlapping elements\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3e7b16-928f-4ec1-8976-e6f33309a194",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetch records from NEET Wide format for the records from Early years table\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3> For records pertaining to early years from 2002 - 2018 we have to retreive data from the NEET Summary Table<br/>\n",
    "    <li> 1. Analyse the records <br/></li>\n",
    "    <li>2. In compliance with the Child Act of 2006, we will exclude data from 2002 to 2005. Subsequently, we will cross-reference records between EYFS and NCCIS, focusing on students aged 16-18 years. <br/></li>\n",
    "    <li> 3. A Student at 5 in 2006 turns 16 in 2017. So we only have 2 years of records to compare <br/></li>\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad815c4d-04cb-4608-8849-7e83b2f2dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instaniate BigQuery client\n",
    "\n",
    "sqlEYFSNEET = \"\"\" SELECT a.person_id,a.AcademicYear,a.Gender,a.PSEAS1,a.PSEAS2,a.PSEAS3,a.PSETotal,\n",
    "    a.CLLAS1,a.CLLAS2,a.CLLAS3,a.CLLAS4,a.CLLTotal,\n",
    "    a.PSRNAS1,a.PSRNAS2,a.PSRNAS3,a.PSRNTotal,\n",
    "    a.RKUW,a.RIPD,a.RICD,a.EYFSPTotal,\n",
    "    a.COMG01,a.COMG02,a.COMG03,a.PHYG04,a.PHYG05,a.PSEG06,a.PSEG07,a.PSEG08,\n",
    "    a.LITG09,a.LITG10,a.MATG11, a.MATG12,a.UTWG13,a.UTWG14,a.UTWG15,a.EXPG16,a.EXPG17,a.GLD, b.* \n",
    "FROM `yhcr-prd-phm-bia-core.CB_FDM_DepartmentForEducation.src_EYFSP` a, `yhcr-prd-phm-bia-core.CB_2166.wide_format_NEET_final` b where a.person_id = b.person_id \"\"\"\n",
    "\n",
    "EYFSPDF = pdg.read_gbq(sqlEYFSNEET, dialect='standard')\n",
    "#sqlWideFormat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5409f3-a98a-42c2-82ee-efc846d4149b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EYFSPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d4e4a-85b9-48ef-bcc9-042d5dd6588c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EYSFTransactDF = EYFSPDF\n",
    "len(EYSFTransactDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f456f-869d-4709-b1c6-5d16cfc47873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EYSFTransactDF = EYSFTransactDF.drop_duplicates(subset=['person_id'])\n",
    "len(EYSFTransactDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16ecba-26a2-4c32-a298-0970bdc6fc97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EYSFTransactDF = EYSFTransactDF.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d657fbe-c63c-4381-96ac-73beb022e345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EYSFTransactDF['newGLD'] = EYSFTransactDF['GLD'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "# EYSFTransactDF['Gender'] = EYSFTransactDF['Gender'].apply(lambda set_: 'F' if (set_== 'f') else set_ )\n",
    "# EYSFTransactDF['Gender'] = EYSFTransactDF['Gender'].apply(lambda set_: 'M' if (set_== 'm') else set_)\n",
    "\n",
    "EYSFTransactDF['newGLD'] = EYSFTransactDF['GLD'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "EYSFTransactDF['Gender'] = EYSFTransactDF['Gender'].apply(lambda set_: 'F' if (set_== 'f') else set_ )\n",
    "EYSFTransactDF['Gender'] = EYSFTransactDF['Gender'].apply(lambda set_: 'M' if (set_== 'm') else set_)\n",
    "EYSFTransactDF[\"AcademicBegin\"]  = EYSFTransactDF[\"AcademicYear\"].str.slice(0, 4)\n",
    "EYSFTransactDF[\"AcademicEnd\"] = EYSFTransactDF[\"AcademicYear\"].str.slice(5)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b15c5-5cae-4aca-8c14-9a69f11c1cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "EYSFTransactDF['PSEAS1'] = EYSFTransactDF['PSEAS1'].replace({None: 0,'N': 0}).astype(int)  \n",
    "EYSFTransactDF['PSEAS2'] = EYSFTransactDF['PSEAS2'].replace({None: 0,'N': 0}).astype(int) \n",
    "EYSFTransactDF['PSEAS3'] = EYSFTransactDF['PSEAS3'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['PSETotal'] = EYSFTransactDF['PSETotal'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['CLLAS1'] = EYSFTransactDF['CLLAS1'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['CLLAS2'] = EYSFTransactDF['CLLAS2'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['CLLAS3'] = EYSFTransactDF['CLLAS3'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['CLLAS4'] = EYSFTransactDF['CLLAS4'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['CLLTotal'] = EYSFTransactDF['CLLTotal'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['PSRNAS1'] = EYSFTransactDF['PSRNAS1'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['PSRNAS2'] = EYSFTransactDF['PSRNAS2'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['PSRNAS3'] = EYSFTransactDF['PSRNAS3'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['PSRNTotal'] = EYSFTransactDF['PSRNTotal'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['RKUW'] = EYSFTransactDF['RKUW'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['RIPD'] = EYSFTransactDF['RIPD'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['RICD'] = EYSFTransactDF['RICD'].replace({None: 0,'N': 0}).astype(int)\n",
    "EYSFTransactDF['EYFSPTotal'] = EYSFTransactDF['EYFSPTotal'].replace({None: 0,'N': 0}).astype(int)\n",
    "\n",
    "EYSFTransactDF['AcademicBegin'] = EYSFTransactDF['AcademicBegin'].astype(int)\n",
    "EYSFTransactDF['AcademicEnd'] = EYSFTransactDF['AcademicEnd'].astype(int)\n",
    "\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f840ad0-a767-484d-957e-b3d76c9261f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EYSFTransactDF = EYSFTransactDF.assign(newGLD=(EYSFTransactDF['PSEAS1']>=6)&(EYSFTransactDF['PSEAS2']>=6)&(EYSFTransactDF['PSEAS3']>=6)&\n",
    "       (EYSFTransactDF['CLLAS1']>=6)&(EYSFTransactDF['CLLAS2']>=6)&(EYSFTransactDF['CLLAS3']>=6)&(EYSFTransactDF['CLLAS4']>=6)&\n",
    "       (EYSFTransactDF['PSRNAS1']>=6)&(EYSFTransactDF['PSRNAS2']>=6)&(EYSFTransactDF['PSRNAS3']>=6)&\n",
    "       (EYSFTransactDF['RKUW']>=6)&(EYSFTransactDF['RICD']>=6)&(EYSFTransactDF['RIPD']>=6)&(EYSFTransactDF['EYFSPTotal']>=78))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c3079-7743-444e-adbf-2309066eeca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EYSFTransactDF.loc[(EYSFTransactDF['PSEAS1']>=6)&(EYSFTransactDF['PSEAS2']>=6)&(EYSFTransactDF['PSEAS3']>=6)&\n",
    "#        (EYSFTransactDF['CLLAS1']>=6)&(EYSFTransactDF['CLLAS2']>=6)&(EYSFTransactDF['CLLAS3']>=6)&(EYSFTransactDF['CLLAS4']>=6)&\n",
    "#        (EYSFTransactDF['PSRNAS1']>=6)&(EYSFTransactDF['PSRNAS2']>=6)&(EYSFTransactDF['PSRNAS3']>=6)&\n",
    "#        (EYSFTransactDF['RKUW']>=6)&(EYSFTransactDF['RICD']>=6)&(EYSFTransactDF['RIPD']>=6)&(EYSFTransactDF['EYFSPTotal']>=78), 'newGLD'] = True   \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991eec4d-6da1-4ff4-b06a-1aa06b1dca52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EYSFTransactDF.loc[(EYSFTransactDF['PSEAS1']>=6)&(EYSFTransactDF['PSEAS2']>=6)&(EYSFTransactDF['PSEAS3']>=6)&\n",
    "#        (EYSFTransactDF['CLLAS1']>=6)&(EYSFTransactDF['CLLAS2']>=6)&(EYSFTransactDF['CLLAS3']>=6)&(EYSFTransactDF['CLLAS4']>=6)&\n",
    "#        (EYSFTransactDF['PSRNAS1']>=6)&(EYSFTransactDF['PSRNAS2']>=6)&(EYSFTransactDF['PSRNAS3']>=6)&\n",
    "#        (EYSFTransactDF['RKUW']>=6)&(EYSFTransactDF['RICD']>=6)&(EYSFTransactDF['RIPD']>=6)&(EYSFTransactDF['EYFSPTotal']>=78)&\n",
    "#        (EYSFTransactDF['newGLD']== False)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e50a1-8bc3-4e31-b3ef-b3bfdb052439",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h2>\n",
    "    1. 47.7% Women students appeared during the academic year 2006-2007 <br/>\n",
    "    2. 52.2% Men students appeared during the academic year 2006-2007 <br/>\n",
    "    </h2>\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea3547-21d1-4a90-98ea-4b69fd0d9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statutaryYears2007_2009 = EYSFTransactDF[EYSFTransactDF[\"AcademicBegin\"]>=2006]\n",
    "statutaryYears2006_2009 = EYSFTransactDF.query(\"AcademicBegin >=2006\")\n",
    "statutaryYears2006_2009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777cdc82-9f24-4db0-a550-7ff77900004d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Due to Statutary limitation remove records from 2002 - 2005 from Early years dataset\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h3> Due to Statutary limitation of the EYFSP - we will avoid the records from 2002-2005</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8248b-ba75-4734-96ae-caf9deac9c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EYSFTransactDF.loc[(EYSFTransactDF['PSEAS1']>=6)&(EYSFTransactDF['PSEAS2']>=6)&(EYSFTransactDF['PSEAS3']>=6)&\n",
    "#        (EYSFTransactDF['CLLAS1']>=6)&(EYSFTransactDF['CLLAS2']>=6)&(EYSFTransactDF['CLLAS3']>=6)&(EYSFTransactDF['CLLAS4']>=6)&\n",
    "#        (EYSFTransactDF['PSRNAS1']>=6)&(EYSFTransactDF['PSRNAS2']>=6)&(EYSFTransactDF['PSRNAS3']>=6)&\n",
    "#        (EYSFTransactDF['RKUW']>=6)&(EYSFTransactDF['RICD']>=6)&(EYSFTransactDF['RIPD']>=6)&(EYSFTransactDF['EYFSPTotal']>=78)&\n",
    "#        (EYSFTransactDF['newGLD']== False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f7b89-ef05-4aee-ad46-36378f16a1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# statutaryYears2006_2009.loc[(statutaryYears2006_2009['PSEAS1']>=6)&(statutaryYears2006_2009['PSEAS2']>=6)&(statutaryYears2006_2009['PSEAS3']>=6)&\n",
    "#        (statutaryYears2006_2009['CLLAS1']>=6)&(statutaryYears2006_2009['CLLAS2']>=6)&(statutaryYears2006_2009['CLLAS3']>=6)&(statutaryYears2006_2009['CLLAS4']>=6)&\n",
    "#        (statutaryYears2006_2009['PSRNAS1']>=6)&(statutaryYears2006_2009['PSRNAS2']>=6)&(statutaryYears2006_2009['PSRNAS3']>=6)&\n",
    "#        (statutaryYears2006_2009['RKUW']>=6)&(statutaryYears2006_2009['RICD']>=6)&(statutaryYears2006_2009['RIPD']>=6)&(statutaryYears2006_2009['newGLD']==False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f200c-b996-4246-a54c-710d888d57d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "statutaryYears2006_2009 = statutaryYears2006_2009.rename(columns={'Persistent_NEET_YN_over_4months':'Persistent_NEET'})\n",
    "#statutaryYears2007_2009.dtypes\n",
    "#statutaryYears2007_2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448b642-1a33-41c6-bfe6-e17fa4144ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disp1 = statutaryYears2006_2009[['person_id','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD','PSETotal','CLLTotal','PSRNTotal','EYFSPTotal','newGLD']]\n",
    "len(disp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334de92-ac3c-41db-91c0-bc1162306d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# disp2 = statutaryYears2007_2009[['person_id','newGLD','COMG01','COMG02','COMG03','PHYG04','PHYG05','PSEG06','PSEG07','PSEG08','LITG09','LITG10','MATG11','MATG12','UTWG13','UTWG14','UTWG15','EXPG16','EXPG17']]\n",
    "# disp2\n",
    "\n",
    "#disp3 = statutaryYears2007_2009[statutaryYears2007_2009['EYFSPTotal'] >= 78]\n",
    "disp3 = disp1[disp1['EYFSPTotal'] >= 78]\n",
    "disp3.newGLD.sum()\n",
    "\n",
    "# len(disp3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04ca7f-b3a5-4d91-8bfe-f8a218ef4819",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the stats on GLD, NEET, Persistent NEET\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3>\n",
    "    <li>1. 5108 records have EYFSP total greater or equal to 78<br/></li>\n",
    "    <li>2. out of 5108, only 2923 records have GLD attainment <br/></li>\n",
    "    <li>3. These records are interesting to probe further as students have scored above the total but have missed on a subject.  further analysis can reveal which subjects students under perform<br/></li> \n",
    "    </h3>\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059589df-36ca-4e52-a107-3e3f29c26678",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3> 2923 students have EYFSPTotal >=78 and have Good Level of Development attaintment True </h3>\n",
    "<h3> 5108 - 2925 = 2183 have EYFSPTotal >= 78 but Good Level of Development attaintment False </h3>\n",
    "# These records are quite interesting for research to see which subjects predicts future NEET #\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f317c3-0353-4ca0-91cc-5d6601a339f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GraphingData = statutaryYears2006_2009.groupby(['AcademicYear','newGLD','Gender']).agg({\n",
    "    'Gender':'value_counts',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum',\n",
    "    #'LSOA_name':'count'\n",
    "    #'newGLD':'value_counts',\n",
    "     }).rename(columns={'Gender':'COUNTByGender'})\n",
    "GraphingData   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0cd67-5318-482f-96e7-60761f683fce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the stats on GLD, Non NEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b2a93-ce50-4c3a-bce8-8e85f79b6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphingNonNeetData = statutaryYears2006_2009.groupby(['AcademicYear','newGLD']).agg({\n",
    "   # 'Gender':'value_counts',\n",
    "    'ever_NEET':lambda x: (x==False).sum(),\n",
    "    'Persistent_NEET':lambda x: (x==False).sum(),\n",
    "    #'LSOA_name':'count'\n",
    "     'newGLD':'value_counts',\n",
    "     }).rename(columns={'newGLD':'COUNTByGLD','ever_NEET':'Non NEET','Persistent_NEET':'Non Persistent_NEET' })\n",
    "GraphingNonNeetData   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ffec2-2e18-4d21-9321-0d953eb1028c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the stats on GLD, Gender and Bradford LSOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b7426-0e16-4602-a9e9-d7a0b1ed22d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GraphingDataLSOA = statutaryYears2006_2009.groupby(['AcademicYear','newGLD','Gender']).agg({\n",
    "    'Gender':'value_counts',\n",
    "    #'ever_NEET':'sum',\n",
    "    #'Persistent_NEET':'sum',\n",
    "    'Bradford_YN':'sum'\n",
    "    #'newGLD':'value_counts',\n",
    "     }).rename(columns={'Gender':'COUNTByGender'})\n",
    "GraphingDataLSOA   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ab85b-38e1-42db-b77e-7cc35beb29e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = GraphingData.reset_index()\n",
    "# plt.bar(X_axis + 0.8, GraphingData['ever_NEET'][2], 0.4, label = 'Female Ever Neet ')\n",
    "# plt.bar(X_axis + 1.2, GraphingData['ever_NEET'][3], 0.4, label = 'Male Ever Neet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f033218-c259-4f2a-b9e2-3382a8c25ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDTrueGenderData = matrix[(matrix['newGLD']==True)]\n",
    "GLDFalseGenderData = matrix[(matrix['newGLD']==False)]\n",
    "GLDTrueGenderData = GLDTrueGenderData.set_index(['AcademicYear','Gender'])\n",
    "print(GLDTrueGenderData)\n",
    "GLDFalseGenderData = GLDFalseGenderData.set_index(['AcademicYear','Gender'])\n",
    "print(GLDFalseGenderData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1abd3-fa5b-42bb-a60b-dfc46935ee9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrixLSOA = GraphingDataLSOA.reset_index()\n",
    "GLDTrueGenderDataLSOA = matrixLSOA[(matrixLSOA['newGLD']==True)]\n",
    "GLDFalseGenderDataLSOA = matrixLSOA[(matrixLSOA['newGLD']==False)]\n",
    "GLDTrueGenderDataLSOA = GLDTrueGenderDataLSOA.set_index(['AcademicYear','Gender'])\n",
    "print(GLDTrueGenderDataLSOA)\n",
    "GLDFalseGenderDataLSOA = GLDFalseGenderDataLSOA.set_index(['AcademicYear','Gender'])\n",
    "print(GLDFalseGenderDataLSOA)\n",
    "\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GLDFalseGenderDataLSOA.drop(GLDFalseGenderDataLSOA.tail(2).index,\n",
    "        inplace = True)\n",
    "lx=GLDFalseGenderDataLSOA.plot(kind='bar')\n",
    "plt.ylabel('Count of people from Bradford LSOA')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "plt.gca().xaxis.set_tick_params(rotation=0)\n",
    "\n",
    "for bar in lx.patches:\n",
    "    height = bar.get_height()\n",
    "    lx.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    lx.set_title(\"count of GLD non attainment based out of Bradford LSOA\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69684ade-5892-4934-b2d4-e4e02bf0f2a8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3>\n",
    "        <div>\n",
    "    2006 - GLD True ->  2914 -Ever NEET ->119 =>4.07%-> Persistent NEET 1.54%  <br/>\n",
    "        -     Female-> 20.01% -> Ever NEET -> 2.2%-> Persistent NEET 0.79% <br/>\n",
    "        -     Male -> 15.50% -> Ever NEET -> 1.78%-> Persistent NEET 0.76% \n",
    "<br/>\n",
    "    2006 - GLD False-> 5290 - Ever NEET ->570 =>10.77%-> Persistent NEET 4.74%  <br/>\n",
    "        -     Female-> 27.74% -> Ever NEET -> 4.04% -> Persistent NEET 1.81% <br/>\n",
    "        -     Male -> 36.74% -> Ever NEET -> 6.72% -> Persistent NEET 2.92%  \n",
    "        </div>\n",
    "<br/>\n",
    "    2007 - GLD True ->  13 - Ever NEET ->1 => 7%\n",
    "<br/>\n",
    "    2007 - GLD False-> 39 - Ever NEET ->1 => 2.56%\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1badc-9056-429d-badc-41e307e5d3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDFalseGenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84846da-87ba-4f2b-837e-ad02c93130be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GLDTrueGenderData.drop(GLDTrueGenderData.tail(2).index,\n",
    "#         inplace = True)\n",
    "ax=GLDTrueGenderData.plot(kind='bar')\n",
    "plt.ylabel('GLD Status by Gender')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "plt.gca().xaxis.set_tick_params(rotation=0)\n",
    "\n",
    "for bar in ax.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    ax.set_title(\"count of GLD attainment True vs NEET based on Gender\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd0f77-69b1-4798-a006-2bcb54debeae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDFalseGenderData.drop(GLDFalseGenderData.tail(2).index,\n",
    "        inplace = True)\n",
    "\n",
    "bx=GLDFalseGenderData.plot(kind='bar')\n",
    "plt.ylabel('GLD Status by Gender')\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "plt.gca().xaxis.set_tick_params(rotation=0)\n",
    "\n",
    "for bar in bx.patches:\n",
    "    height = bar.get_height()\n",
    "    bx.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    bx.set_title(\"count of GLD attainment False vs NEET based on Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef39d3f-e562-4cf2-94e6-3e62031c1ad5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the stats on correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095223b-cee1-4afb-a7cd-b558c4e6e14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrDF = statutaryYears2006_2009[['newGLD','ever_NEET','Persistent_NEET','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD','PSETotal','CLLTotal','PSRNTotal','EYFSPTotal']]\n",
    "\n",
    "pearson=corrDF.corr(method='pearson')\n",
    "pearson\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(corrDF.corr(method='pearson'),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822e857-e4bd-44d5-962b-c0d7c4b66b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0894d24-98e6-4aee-b8cd-c8faf07fa347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=statutaryYears2006_2009[['RIPD','RICD','RKUW','PSETotal','CLLTotal','PSRNTotal','EYFSPTotal']]\n",
    "y=statutaryYears2006_2009[['newGLD']]\n",
    "### The data has to be divided in training and test set. \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2785d1-94f6-49da-b2f3-ffa9199ae83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(statutaryYears2006_2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3dbb8-9460-48f3-81ff-71476a8872d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GLDTrueGenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8877647-6138-4b19-a218-807f03ac92f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GLDFalseGenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f703ada-7dcd-42a6-a60d-fef7607c719b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDTrueData = GLDTrueGenderData.reset_index()\n",
    "GLDFalseData = GLDFalseGenderData.reset_index()\n",
    "GLDFalseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346f697-aa12-4cf2-bfa5-ce581e46b86e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLDFailedCount = GLDFalseData.COUNTByGender[0] + GLDFalseData.COUNTByGender[1]\n",
    "GLDFailedCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26d3f7-0740-441a-a92b-8d8ebb176c76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the stats on GLD, and number of students who have scored less than 6 in each of the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e2927-5f64-486b-8e72-0ef8dc5cd4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets find out the number of students who has failed to attaintment condition\n",
    "\n",
    "statsCountNEET = statutaryYears2006_2009.groupby(['AcademicYear', 'newGLD']).agg({ \n",
    "    'newGLD':'count',\n",
    "    'ever_NEET':lambda x: (x==True).sum(),\n",
    "    'Persistent_NEET': lambda x: (x==True).sum(),\n",
    "    'PSEAS1':lambda ts: (ts < 6).sum(),\n",
    "    'PSEAS2':lambda ts: (ts < 6).sum(),\n",
    "    'PSEAS3':lambda ts: (ts < 6).sum(),\n",
    "   # 'PSETotal': 'sum',\n",
    "    'CLLAS1':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS2':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS3':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS4':lambda ts: (ts < 6).sum(),\n",
    "   # 'CLLTotal':'sum',\n",
    "    'PSRNAS1':lambda ts: (ts < 6).sum(),\n",
    "    'PSRNAS2':lambda ts: (ts < 6).sum(),\n",
    "    'PSRNAS3':lambda ts: (ts < 6).sum(),\n",
    "   # 'PSRNTotal':lambda ts: (ts >= 6).sum(),\n",
    "    'RKUW':lambda ts: (ts < 6).sum(),\n",
    "    'RIPD':lambda ts: (ts < 6).sum(),\n",
    "    'RICD':lambda ts: (ts < 6).sum(),\n",
    "    'EYFSPTotal':lambda ts: (ts <78 ).sum()\n",
    "    }).rename(columns={'newGLD':'COUNTByGLD'})\n",
    "\n",
    "statsCountNEET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a3b02-383e-44de-b455-3fcae9cbb44b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To get the stats on GLD, and number of students who have scored greater than or equal to 6 in each of the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea39235-9768-450b-9046-c86cb0d012d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets find out the number of students who has passed to attaintment condition\n",
    "\n",
    "statsPassCountNEET = statutaryYears2006_2009.groupby(['AcademicYear', 'newGLD']).agg({ \n",
    "    #'newGLD':lambda x: (x==False).sum(),\n",
    "    'newGLD':'count',\n",
    "    'ever_NEET':lambda x: (x==True).sum(),\n",
    "    'Persistent_NEET': lambda x: (x==True).sum(),\n",
    "    'PSEAS1':lambda ts: (ts >= 6).sum(),\n",
    "    'PSEAS2':lambda ts: (ts >= 6).sum(),\n",
    "    'PSEAS3':lambda ts: (ts >= 6).sum(),\n",
    "   # 'PSETotal': 'sum',\n",
    "    'CLLAS1':lambda ts: (ts >= 6).sum(),\n",
    "    'CLLAS2':lambda ts: (ts >= 6).sum(),\n",
    "    'CLLAS3':lambda ts: (ts >= 6).sum(),\n",
    "    'CLLAS4':lambda ts: (ts >= 6).sum(),\n",
    "   # 'CLLTotal':'sum',\n",
    "    'PSRNAS1':lambda ts: (ts >= 6).sum(),\n",
    "    'PSRNAS2':lambda ts: (ts >= 6).sum(),\n",
    "    'PSRNAS3':lambda ts: (ts >= 6).sum(),\n",
    "   # 'PSRNTotal':lambda ts: (ts >= 6).sum(),\n",
    "    'RKUW':lambda ts: (ts >= 6).sum(),\n",
    "    'RIPD':lambda ts: (ts >= 6).sum(),\n",
    "    'RICD':lambda ts: (ts >= 6).sum(),\n",
    "    'EYFSPTotal':lambda ts: (ts >=78 ).sum()\n",
    "    }).rename(columns={'newGLD':'COUNTByGLD'})\n",
    "\n",
    "statsPassCountNEET\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04601688-3ef0-415e-ac2f-eabb563f06f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gender based GLD non attainment plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623a776-7478-4321-9a25-9831e0ec214e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sumvalALL = (statsCountNEET/5287)*100\n",
    "sumvalALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54b465-07a1-42c9-992f-27043214da62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets find out the number of students who has failed to attaintment condition\n",
    "\n",
    "test_Fail_EYFSP = statutaryYears2006_2009.groupby(['AcademicYear','newGLD','Gender']).agg({\n",
    "    'Gender':'count', \n",
    "    #'newGLD':lambda x: (x==False).sum(),\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum',\n",
    "    'PSEAS1':lambda ts: (ts < 6).sum(),\n",
    "    'PSEAS2':lambda ts: (ts < 6).sum(),\n",
    "    'PSEAS3':lambda ts: (ts < 6).sum(),\n",
    "   # 'PSETotal': 'sum',\n",
    "    'CLLAS1':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS2':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS3':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS4':lambda ts: (ts < 6).sum(),\n",
    "   # 'CLLTotal':'sum',\n",
    "    'PSRNAS1':lambda ts: (ts < 6).sum(),\n",
    "    'PSRNAS2':lambda ts: (ts < 6).sum(),\n",
    "    'PSRNAS3':lambda ts: (ts < 6).sum(),\n",
    "   # 'PSRNTotal':lambda ts: (ts >= 6).sum(),\n",
    "    'RKUW':lambda ts: (ts < 6).sum(),\n",
    "    'RIPD':lambda ts: (ts < 6).sum(),\n",
    "    'RICD':lambda ts: (ts < 6).sum(),\n",
    "    'EYFSPTotal':lambda ts: (ts <78 ).sum()\n",
    "    }).rename(columns={'Gender':'COUNTByGender'})\n",
    "\n",
    "test_Fail_EYFSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3614b-1fc7-49fc-bb60-6a3349d005c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sumval = (test_Fail_EYFSP/5287)*100\n",
    "sumval\n",
    "\n",
    "genderPercentOver = sumval.reset_index()\n",
    "genderPercentOver.drop(genderPercentOver.tail(4).index,\n",
    "        inplace = True)\n",
    "genderPercentOverFemale = genderPercentOver.query(\"newGLD == False & Gender.str.contains('F')\")\n",
    "genderPercentOverMale = genderPercentOver.query(\"newGLD == False & Gender.str.contains('M')\")\n",
    "\n",
    "#labels1 = ['PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD']\n",
    "genderPercentOverFemale= genderPercentOverFemale[['ever_NEET','Persistent_NEET','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD']]\n",
    "genderPercentOverMale= genderPercentOverMale[['ever_NEET','Persistent_NEET','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD']]\n",
    "genderPercentOverMale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11188d7a-7466-4be4-a81b-aa99a09799ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PercentOver = sumvalALL.reset_index()\n",
    "PercentOver.drop(PercentOver.tail(2).index,\n",
    "        inplace = True)\n",
    "PercentOverGP = PercentOver.query(\"newGLD == False\")\n",
    "PercentOverGP= PercentOverGP[['newGLD','ever_NEET','Persistent_NEET','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD']]\n",
    "PercentOverGP = PercentOverGP.rename(columns={'PSEAS1':'Personal Social Emotional - readiness Classroom',\n",
    "                      'PSEAS2':'Personal Social Emotional - readiness Relationship',\n",
    "                      'PSEAS3':'Personal Social Emotional - readiness Expressive',\n",
    "                      'CLLAS1':'Communication, language, literacy - Listening',\n",
    "                      'CLLAS2':'Communication, language, literacy - Reading',\n",
    "                      'CLLAS3':'Communication, language, literacy - Reading Books',\n",
    "                      'CLLAS4':'Communication, language, literacy - Communication',\n",
    "                      'PSRNAS1':'Problem solving Reasoning and Numeracy - Counting',\n",
    "                      'PSRNAS2':'Problem solving Reasoning and Numeracy - Recognition',\n",
    "                      'PSRNAS3':'Problem solving Reasoning and Numeracy - Practicing',\n",
    "                      'RKUW':'Understanding of the World',\n",
    "                      'RIPD':'Physical Development',\n",
    "                      'RICD':'Creative Development'})\n",
    "PercentOverGP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7dca62-c74f-4a05-ac96-fe0fb5fca60e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A different approach un comment later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a8fe1-a0c3-4639-a945-0b1b34893039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PercentPassOver = sumvalALL.reset_index()\n",
    "# print(PercentPassOver)\n",
    "# PercentPassOver.drop(PercentPassOver.tail(2).index,\n",
    "#         inplace = True)\n",
    "# PercentPassOver = PercentPassOver.query(\"newGLD == True\")\n",
    "# PercentPassOver= PercentPassOver[['newGLD','ever_NEET','Persistent_NEET','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RICD','RIPD']]\n",
    "# PercentPassOver = PercentPassOver.rename(columns={'PSEAS1':'Personal Social Emotional - readiness Classroom',\n",
    "#                       'PSEAS2':'Personal Social Emotional - readiness Relationship',\n",
    "#                       'PSEAS3':'Personal Social Emotional - readiness Expressive',\n",
    "#                       'CLLAS1':'Communication, language, literacy - Listening',\n",
    "#                       'CLLAS2':'Communication, language, literacy - Reading',\n",
    "#                       'CLLAS3':'Communication, language, literacy - Reading Books',\n",
    "#                       'CLLAS4':'Communication, language, literacy - Communication',\n",
    "#                       'PSRNAS1':'Problem solving Reasoning and Numeracy - Counting',\n",
    "#                       'PSRNAS2':'Problem solving Reasoning and Numeracy - Recognition',\n",
    "#                       'PSRNAS3':'Problem solving Reasoning and Numeracy - Practicing',\n",
    "#                       'RKUW':'Understanding of the World',\n",
    "#                       'RIPD':'Physical Development',\n",
    "#                       'RICD':'Creative Development'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27909e6a-1c8a-45d4-b922-aae9b8c4d3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pfs = PercentPassOver\n",
    "# print(pfs)\n",
    "# pfs1 = pd.melt(pfs, id_vars = \"newGLD\")\n",
    "\n",
    "# pfs1 = pfs1.rename(columns={\"variable\": \"NEET and Domains\"})\n",
    "# print(pfs1)\n",
    "\n",
    "# g=sns.catplot(x = 'newGLD', y='value',hue = 'NEET and Domains',data=pfs1, kind='bar', width = 1, legend=True, height=6, aspect=2, palette = 'pastel')\n",
    "# ax = g.facet_axis(0, 0)  # or ax = g.axes.flat[0]\n",
    "\n",
    "# # iterate through the axes containers\n",
    "# for c in ax.containers:\n",
    "#     labels = [f'{(v.get_height() ):.1f}' for v in c]\n",
    "#     ax.bar_label(c, labels=labels, label_type='edge')\n",
    "# #sns.despine()\n",
    "# plt.title(\"GLD Passed percenatge w.r.t NEET and Domains\")\n",
    "# plt.xlabel(\"Percentage Passed in Good Level of Development Domain wise\")\n",
    "# #plt.xticks(rotation=90)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbc18f-f8de-443e-a3aa-0648100a1b5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualising the GLD non attainment percentages across the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf3a8e-a386-4d43-8291-0a0919350618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "tfs = PercentOverGP\n",
    "#print(tfs)\n",
    "tfs1 = pd.melt(tfs, id_vars = \"newGLD\")\n",
    "\n",
    "tfs1 = tfs1.rename(columns={\"variable\": \"NEET and Domains\"})\n",
    "#print(tfs1)\n",
    "\n",
    "g=sns.catplot(x = 'newGLD', y='value',hue = 'NEET and Domains',data=tfs1, kind='bar', width = 1, legend=True, height=6, aspect=2, palette = 'pastel')\n",
    "ax = g.facet_axis(0, 0)  # or ax = g.axes.flat[0]\n",
    "\n",
    "# iterate through the axes containers\n",
    "for c in ax.containers:\n",
    "    labels = [f'{(v.get_height() ):.1f}' for v in c]\n",
    "    ax.bar_label(c, labels=labels, label_type='edge')\n",
    "#sns.despine()\n",
    "plt.title(\"GLD Failed percenatge w.r.t NEET and Domains\")\n",
    "plt.xlabel(\"Percentage failure in Good Level of Development Domain wise\")\n",
    "#plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62513c42-0614-4351-949f-35ca86b55810",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gender based Visualising the GLD non attainment percentages across the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360412f-5d46-4aac-8460-257e4a6dbb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(24,12))\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "genderPercentOverFemale.plot(kind='bar',ax=ax1)\n",
    "ax1.set_ylabel('subject by percentages')\n",
    "\n",
    "for bar in ax1.patches:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=12,\n",
    "            ha='center')\n",
    "    ax1.set_title(\"Percentage of GLD non attainment by Female\")\n",
    "    \n",
    "\n",
    "genderPercentOverMale.plot(kind='bar', ax=ax2)\n",
    "ax2.set_ylabel('subject by percentages')\n",
    "for bar in ax2.patches:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=12,\n",
    "            ha='center')\n",
    "    ax2.set_title(\"Percentage of GLD non attainment by Male\")\n",
    "    \n",
    "plt.show() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a529e3-192f-4684-b05c-52cd5c349d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#overall = test_Fail_EYFSP.groupby(level=0).transform('sum')\n",
    "# overall = sumval.groupby(level=0).transform('sum')\n",
    "# overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f170a3-b77a-4697-a6c3-64be96ccf9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets find out the number of students who has failed to attaintment condition\n",
    "\n",
    "test_Fail_EYFSP_all = statutaryYears2006_2009.groupby(['AcademicYear', 'newGLD']).agg({\n",
    "   # 'newGLD':lambda x: (x==False).sum(),\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum',\n",
    "    'PSEAS1':lambda ts: (ts < 6).sum(),\n",
    "    'PSEAS2':lambda ts: (ts < 6).sum(),\n",
    "    'PSEAS3':lambda ts: (ts < 6).sum(),\n",
    "   # 'PSETotal': 'sum',\n",
    "    'CLLAS1':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS2':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS3':lambda ts: (ts < 6).sum(),\n",
    "    'CLLAS4':lambda ts: (ts < 6).sum(),\n",
    "   # 'CLLTotal':'sum',\n",
    "    'PSRNAS1':lambda ts: (ts < 6).sum(),\n",
    "    'PSRNAS2':lambda ts: (ts < 6).sum(),\n",
    "    'PSRNAS3':lambda ts: (ts < 6).sum(),\n",
    "   # 'PSRNTotal':lambda ts: (ts >= 6).sum(),\n",
    "    'RKUW':lambda ts: (ts < 6).sum(),\n",
    "    'RIPD':lambda ts: (ts < 6).sum(),\n",
    "    'RICD':lambda ts: (ts < 6).sum(),\n",
    "    'EYFSPTotal':lambda ts: (ts <78 ).sum()\n",
    "    }).rename(columns={'PSEAS1':'Personal Social Emotional - readiness Classroom',\n",
    "                      'PSEAS2':'Personal Social Emotional - readiness Relationship',\n",
    "                      'PSEAS3':'Personal Social Emotional - readiness Expressive',\n",
    "                      'CLLAS1':'Communication, language, literacy - Listening',\n",
    "                      'CLLAS2':'Communication, language, literacy - Reading',\n",
    "                      'CLLAS3':'Communication, language, literacy - Reading Books',\n",
    "                      'CLLAS4':'Communication, language, literacy - Communication',\n",
    "                      'PSRNAS1':'Problem solving Reasoning and Numeracy - Counting',\n",
    "                      'PSRNAS2':'Problem solving Reasoning and Numeracy - Recognition',\n",
    "                      'PSRNAS3':'Problem solving Reasoning and Numeracy - Practicing',\n",
    "                      'RKUW':'Understanding of the World',\n",
    "                      'RIPD':'Physical Development',\n",
    "                      'RICD':'Creative Development'})\n",
    "\n",
    "test_Fail_EYFSP_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c6d64-ca50-48d9-b98e-0aa92280d604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sumvalAll = (test_Fail_EYFSP_all/5285)*100\n",
    "\n",
    "PercentOverAll = sumvalAll.reset_index()\n",
    "PercentOverAll.drop(PercentOverAll.tail(2).index,inplace = True)\n",
    "PercentOverAll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b6e9a-fe05-4a0f-8f70-5bc551376bac",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3271c40-e301-4339-b829-ce8ce5c4186f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "        <div>\n",
    "    1. CLLAS4 - Communication, Language and Literacy - Roughly 47% failed in this subject <br/>\n",
    "            <li> uses phonic knowledge to write simple regular words </li>\n",
    "            <li>begins to form captions and simple sentences, sometimes using punctuation</li>\n",
    "            <li>communicates meaning through phrases and simple sentences </li><br/>\n",
    "    2. CLLAS2 - Communication, Language and Literacy - Roughly 39.3% failed in this subject <br/>\n",
    "            <li>uses phonic knowledge to read simple regular words </li>\n",
    "            <li>attempts to read more complex words, using phonic knowledge</li>\n",
    "            <li>uses knowledge of letters, sounds and words when reading and writing independently </li><br/>       \n",
    "    3. PSRNAS2 - Problem Solving, Reasoning and Numeracy - Roughly 38% failed in this subject<br/>\n",
    "            <li> in practical activities and discussion, begins to use the vocabulary involved in adding and subtracting </li>\n",
    "            <li> uses developing mathematical ideas and methods to solve practical problems</li>\n",
    "            <li>uses a range of strategies for addition and subtraction, inclusion some mental recall of number bonds </li><br/>\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3b2bd-8751-497b-b160-c8c117240b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting up domain wise failure flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5369d8-f94c-45ba-8a10-a75ed1059e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets find out the number of students who has failed to attaintment condition\n",
    "test_Fail_all_EYFSP=statutaryYears2006_2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7a4e3-c96b-4959-8f56-70535ccfca4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(allSubjecttFail=(test_Fail_all_EYFSP['PSEAS1']<6)&(test_Fail_all_EYFSP['PSEAS2']<6)&(test_Fail_all_EYFSP['PSEAS3']<6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']<6)&(test_Fail_all_EYFSP['CLLAS2']<6)&(test_Fail_all_EYFSP['CLLAS3']<6)&(test_Fail_all_EYFSP['CLLAS4']<6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']<6)&(test_Fail_all_EYFSP['PSRNAS2']<6)&(test_Fail_all_EYFSP['PSRNAS3']<6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']<6)&(test_Fail_all_EYFSP['RICD']<6)&(test_Fail_all_EYFSP['RIPD']<6)&(test_Fail_all_EYFSP['EYFSPTotal']<78))\n",
    "test_Fail_all_EYFSP.allSubjecttFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f963336-2246-439d-9328-5aee538d4726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSEAS1EXCFail=(test_Fail_all_EYFSP['PSEAS1']<6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.PSEAS1EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d655e-0549-4f3a-9d7d-3426d7271977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSEAS2EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']<6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.PSEAS2EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984b1dc-5d0f-486f-947e-d2bfbdaa9674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSEAS3EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']<6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.PSEAS3EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3c73c-9d84-4eb9-82d9-3a8425c53af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS1EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']<6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.CLLAS1EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3fdc85-2eee-40b3-a455-6a0778633b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS2EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']<6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.CLLAS2EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf5d25-cd0e-4fb2-a509-57e75929b57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS3EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']<6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.CLLAS3EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562b5ac-ebe6-4f13-a7e6-235a1f78bc43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS4EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']<6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.CLLAS4EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d517f-a966-4247-a55d-2f11d54e3c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNAS1EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']<6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.PSRNAS1EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11a4df-3f06-42dc-8369-d0089c7609cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNAS2EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']<6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.PSRNAS2EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5784c9-0e7d-4086-9639-788d4e5a6d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNAS3EXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']<6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6))\n",
    "test_Fail_all_EYFSP.PSRNAS3EXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d1951-1192-4f02-8636-bfb990aecf33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(RKUWEXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']<6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']>=6)) \n",
    "test_Fail_all_EYFSP.RKUWEXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526746e-bd49-434b-9b61-efbd72c97e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(RICDEXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']<6)&(test_Fail_all_EYFSP['RIPD']>=6))                                               \n",
    "test_Fail_all_EYFSP.RICDEXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91210d-7a3a-40ff-a70d-99bf837153a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(RIPDEXCFail=(test_Fail_all_EYFSP['PSEAS1']>=6)&(test_Fail_all_EYFSP['PSEAS2']>=6)&(test_Fail_all_EYFSP['PSEAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['CLLAS1']>=6)&(test_Fail_all_EYFSP['CLLAS2']>=6)&(test_Fail_all_EYFSP['CLLAS3']>=6)&(test_Fail_all_EYFSP['CLLAS4']>=6)&\n",
    "       (test_Fail_all_EYFSP['PSRNAS1']>=6)&(test_Fail_all_EYFSP['PSRNAS2']>=6)&(test_Fail_all_EYFSP['PSRNAS3']>=6)&\n",
    "       (test_Fail_all_EYFSP['RKUW']>=6)&(test_Fail_all_EYFSP['RICD']>=6)&(test_Fail_all_EYFSP['RIPD']<6)) \n",
    "test_Fail_all_EYFSP.RIPDEXCFail.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1da2b-f49f-408d-aca3-6aa7dda58b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_Fail_all_EYFSP.loc[(test_Fail_all_EYFSP['EYFSPTotal']<78), 'EYFSPTOTFail'] = True   \n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(EYFSPTOTFail=(test_Fail_all_EYFSP['EYFSPTotal'] < 78))\n",
    "\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSEAS1Fail=(test_Fail_all_EYFSP['PSEAS1'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSEAS2Fail=(test_Fail_all_EYFSP['PSEAS2'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSEAS3Fail=(test_Fail_all_EYFSP['PSEAS3'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSETotalFail=((test_Fail_all_EYFSP['PSEAS1'] < 6) | (test_Fail_all_EYFSP['PSEAS2'] < 6) |\n",
    "                                                               (test_Fail_all_EYFSP['PSEAS3'] < 6)))\n",
    "                                                                                                 \n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS1Fail=(test_Fail_all_EYFSP['CLLAS1'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS2Fail=(test_Fail_all_EYFSP['CLLAS2'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS3Fail=(test_Fail_all_EYFSP['CLLAS3'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLAS4Fail=(test_Fail_all_EYFSP['CLLAS4'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(CLLTotalFail=((test_Fail_all_EYFSP['CLLAS1'] < 6)|(test_Fail_all_EYFSP['CLLAS2'] < 6)|\n",
    "                                                               (test_Fail_all_EYFSP['CLLAS3'] < 6)| (test_Fail_all_EYFSP['CLLAS4'] < 6)))\n",
    "\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNAS1Fail=(test_Fail_all_EYFSP['PSRNAS1'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNAS2Fail=(test_Fail_all_EYFSP['PSRNAS2'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNAS3Fail=(test_Fail_all_EYFSP['PSRNAS3'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(PSRNTotalFail=((test_Fail_all_EYFSP['PSRNAS1'] < 6)|(test_Fail_all_EYFSP['PSRNAS2'] < 6)|\n",
    "                                                                (test_Fail_all_EYFSP['PSRNAS3'] < 6)))\n",
    "                                                \n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(RKUWFAIL=(test_Fail_all_EYFSP['RKUW'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(RICDFAIL=(test_Fail_all_EYFSP['RICD'] < 6))\n",
    "test_Fail_all_EYFSP = test_Fail_all_EYFSP.assign(RIPDFAIL=(test_Fail_all_EYFSP['RIPD'] < 6))                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d52df-e8e1-4b31-b24c-c8fac36bda35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_Fail_all_EYFSP.loc[(test_Fail_all_EYFSP['allSubjecttFail']==False)&(test_Fail_all_EYFSP['newGLD']==False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8ae75-24ce-4ec2-972f-c55c435b053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_Fail_all_EYFSPY1 = test_Fail_all_EYFSP.query('AcademicYear == \"2006/2007\"')\n",
    "test_Fail_all_EYFSPY1 = test_Fail_all_EYFSPY1.drop(['person_id_1','percentage_time_neet','COMG01','COMG02','COMG03','PHYG04','PHYG05','PSEG06','PSEG07','PSEG08','LITG09','LITG10','MATG11','MATG12','UTWG13','UTWG14','UTWG15','EXPG16','EXPG17'],axis=1)\n",
    "test_Fail_all_EYFSPY1.EYFSPTOTFail.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296c9bc-e302-4fbe-a254-12652c5c5d2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Manipulating the flags indicating failure in each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccd4aa-e626-4972-bd86-269870aae84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ****************************************************\n",
    "# For All Comm, Language, Literacy\n",
    "# ****************************************************\n",
    "\n",
    "\n",
    "countCLLTot = test_Fail_all_EYFSPY1.groupby(['CLLTotalFail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'CLLTotalFail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'CLLTotalFail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countCLLTotPass = countCLLTot.reset_index()\n",
    "countCLLTotFail = countCLLTot.reset_index()\n",
    "\n",
    "countCLLTotPass['Domain'] = \"Comm, Lang, Literacy\"\n",
    "countCLLTotFail['Domain'] = \"Comm, Lang, Literacy\"\n",
    "\n",
    "countCLLTotFail = countCLLTotFail[countCLLTotFail['CLLTotalFail'] == True].drop(['CLLTotalFail'], axis=1)\n",
    "countCLLTotPass = countCLLTotPass[countCLLTotPass['CLLTotalFail'] == False].drop(['CLLTotalFail'], axis=1)\n",
    "\n",
    "print(countCLLTotPass)\n",
    "print(countCLLTotFail)\n",
    "\n",
    "\n",
    "\n",
    "countCLLAS1 = test_Fail_all_EYFSPY1.groupby(['CLLAS1Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'CLLAS1Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'CLLAS1Fail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countCLLAS1Pass = countCLLAS1.reset_index()\n",
    "countCLLAS1Fail = countCLLAS1.reset_index()\n",
    "\n",
    "countCLLAS1Pass['Domain'] = \"Comm, Lang, Lit Listening CLLAS1\"\n",
    "countCLLAS1Fail['Domain'] = \"Comm, Lang, Lit Listening CLLAS1\"\n",
    "\n",
    "countCLLAS1Fail = countCLLAS1Fail[countCLLAS1Fail['CLLAS1Fail'] == True].drop(['CLLAS1Fail'], axis=1)\n",
    "countCLLAS1Pass = countCLLAS1Pass[countCLLAS1Pass['CLLAS1Fail'] == False].drop(['CLLAS1Fail'], axis=1)\n",
    "\n",
    "print(countCLLAS1Pass)\n",
    "print(countCLLAS1Fail)\n",
    "\n",
    "# ***********\n",
    "# CLLAS2\n",
    "# ***********\n",
    "countCLLAS2 = test_Fail_all_EYFSPY1.groupby(['CLLAS2Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'CLLAS2Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'CLLAS2Fail':'Count'})\n",
    "#print(countCLLAS2)\n",
    "countCLLAS2Pass = countCLLAS2.reset_index()\n",
    "countCLLAS2Fail = countCLLAS2.reset_index()\n",
    "\n",
    "countCLLAS2Pass['Domain'] = \"Comm, Lang, Lit Rhyming CLLAS2\"\n",
    "countCLLAS2Fail['Domain'] = \"Comm, Lang, Lit Rhyming CLLAS2\"\n",
    "\n",
    "countCLLAS2Fail = countCLLAS2Fail[countCLLAS2Fail['CLLAS2Fail'] == True].drop(['CLLAS2Fail'], axis=1)\n",
    "countCLLAS2Pass = countCLLAS2Pass[countCLLAS2Pass['CLLAS2Fail'] == False].drop(['CLLAS2Fail'], axis=1)\n",
    "\n",
    "print(countCLLAS2Pass)\n",
    "print(countCLLAS2Fail)\n",
    "\n",
    "# ***********\n",
    "# CLLAS3\n",
    "# ***********\n",
    "countCLLAS3 = test_Fail_all_EYFSPY1.groupby(['CLLAS3Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'CLLAS3Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'CLLAS3Fail':'Count'})\n",
    "#print(countCLLAS3)\n",
    "countCLLAS3Pass = countCLLAS3.reset_index()\n",
    "countCLLAS3Fail = countCLLAS3.reset_index()\n",
    "\n",
    "countCLLAS3Pass['Domain'] = \"Comm, Lang, Lit Reading CLLAS3\"\n",
    "countCLLAS3Fail['Domain'] = \"Comm, Lang, Lit Reading CLLAS3\"\n",
    "\n",
    "countCLLAS3Fail = countCLLAS3Fail[countCLLAS3Fail['CLLAS3Fail'] == True].drop(['CLLAS3Fail'], axis=1)\n",
    "countCLLAS3Pass = countCLLAS3Pass[countCLLAS3Pass['CLLAS3Fail'] == False].drop(['CLLAS3Fail'], axis=1)\n",
    "\n",
    "print(countCLLAS3Pass)\n",
    "print(countCLLAS3Fail)\n",
    "\n",
    "# ***********\n",
    "# CLLAS4\n",
    "# ***********\n",
    "countCLLAS4 = test_Fail_all_EYFSPY1.groupby(['CLLAS4Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'CLLAS4Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'CLLAS4Fail':'Count'})\n",
    "#print(countCLLAS4)\n",
    "countCLLAS4Pass = countCLLAS4.reset_index()\n",
    "countCLLAS4Fail = countCLLAS4.reset_index()\n",
    "\n",
    "countCLLAS4Pass['Domain'] = \"Comm, Lang, Lit Writing CLLAS4\"\n",
    "countCLLAS4Fail['Domain'] = \"Comm, Lang, Lit Writing CLLAS4\"\n",
    "\n",
    "countCLLAS4Fail = countCLLAS4Fail[countCLLAS4Fail['CLLAS4Fail'] == True].drop(['CLLAS4Fail'], axis=1)\n",
    "countCLLAS4Pass = countCLLAS4Pass[countCLLAS4Pass['CLLAS4Fail'] == False].drop(['CLLAS4Fail'], axis=1)\n",
    "\n",
    "print(countCLLAS4Pass)\n",
    "print(countCLLAS4Fail)\n",
    "\n",
    "# 'countCLLAS1Pass', 'countCLLAS1Fail','countCLLAS2Pass','countCLLAS2Fail','countCLLAS3Pass','countCLLAS3Fail','countCLLAS4Pass','countCLLAS4Fail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabeac23-a580-4d82-9d37-f3272d040984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ****************************************************\n",
    "# For All Personal, Social, Emotional\n",
    "# ****************************************************\n",
    "\n",
    "\n",
    "countPSETot = test_Fail_all_EYFSPY1.groupby(['PSETotalFail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSETotalFail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSETotalFail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countPSETotPass = countPSETot.reset_index()\n",
    "countPSETotFail = countPSETot.reset_index()\n",
    "\n",
    "countPSETotPass['Domain'] = \"Personal, Social motivation\"\n",
    "countPSETotFail['Domain'] = \"Personal, Social motivation\"\n",
    "\n",
    "countPSETotFail = countPSETotFail[countPSETotFail['PSETotalFail'] == True].drop(['PSETotalFail'], axis=1)\n",
    "countPSETotPass = countPSETotPass[countPSETotPass['PSETotalFail'] == False].drop(['PSETotalFail'], axis=1)\n",
    "\n",
    "print(countPSETotPass)\n",
    "print(countPSETotFail)\n",
    "\n",
    "\n",
    "countPSEAS1 = test_Fail_all_EYFSPY1.groupby(['PSEAS1Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSEAS1Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSEAS1Fail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countPSEAS1Pass = countPSEAS1.reset_index()\n",
    "countPSEAS1Fail = countPSEAS1.reset_index()\n",
    "\n",
    "countPSEAS1Pass['Domain'] = \"Personal, Social motivation PSEAS1\"\n",
    "countPSEAS1Fail['Domain'] = \"Personal, Social motivation PSEAS1\"\n",
    "\n",
    "countPSEAS1Fail = countPSEAS1Fail[countPSEAS1Fail['PSEAS1Fail'] == True].drop(['PSEAS1Fail'], axis=1)\n",
    "countPSEAS1Pass = countPSEAS1Pass[countPSEAS1Pass['PSEAS1Fail'] == False].drop(['PSEAS1Fail'], axis=1)\n",
    "\n",
    "print(countPSEAS1Pass)\n",
    "print(countPSEAS1Fail)\n",
    "\n",
    "# ***********\n",
    "# PSEAS2\n",
    "# ***********\n",
    "countPSEAS2 = test_Fail_all_EYFSPY1.groupby(['PSEAS2Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSEAS2Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSEAS2Fail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countPSEAS2Pass = countPSEAS2.reset_index()\n",
    "countPSEAS2Fail = countPSEAS2.reset_index()\n",
    "\n",
    "countPSEAS2Pass['Domain'] = \"Personal, Social relationship PSEAS2\"\n",
    "countPSEAS2Fail['Domain'] = \"Personal, Social relationship PSEAS2\"\n",
    "\n",
    "countPSEAS2Fail = countPSEAS2Fail[countPSEAS2Fail['PSEAS2Fail'] == True].drop(['PSEAS2Fail'], axis=1)\n",
    "countPSEAS2Pass = countPSEAS2Pass[countPSEAS2Pass['PSEAS2Fail'] == False].drop(['PSEAS2Fail'], axis=1)\n",
    "\n",
    "print(countPSEAS2Pass)\n",
    "print(countPSEAS2Fail)\n",
    "\n",
    "# ***********\n",
    "# PSEAS3\n",
    "# ***********\n",
    "countPSEAS3 = test_Fail_all_EYFSPY1.groupby(['PSEAS3Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSEAS3Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSEAS3Fail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countPSEAS3Pass = countPSEAS3.reset_index()\n",
    "countPSEAS3Fail = countPSEAS3.reset_index()\n",
    "\n",
    "countPSEAS3Pass['Domain'] = \"Personal, Social awareness PSEAS3\"\n",
    "countPSEAS3Fail['Domain'] = \"Personal, Social awareness PSEAS3\"\n",
    "\n",
    "countPSEAS3Fail = countPSEAS3Fail[countPSEAS3Fail['PSEAS3Fail'] == True].drop(['PSEAS3Fail'], axis=1)\n",
    "countPSEAS3Pass = countPSEAS3Pass[countPSEAS3Pass['PSEAS3Fail'] == False].drop(['PSEAS3Fail'], axis=1)\n",
    "\n",
    "print(countPSEAS3Pass)\n",
    "print(countPSEAS3Fail)\n",
    "\n",
    "# 'countPSEAS1Pass','countPSEAS1Fail','countPSEAS2Pass','countPSEAS2Fail','countPSEAS3Pass','countPSEAS3Fail'\n",
    "# 'countCLLAS1Pass', 'countCLLAS1Fail','countCLLAS2Pass','countCLLAS2Fail','countCLLAS3Pass','countCLLAS3Fail','countCLLAS4Pass','countCLLAS4Fail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe2225-1be6-4a3c-bea0-f758ea5543ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ****************************************************\n",
    "# For All problem solving, reasoning, numeracy\n",
    "# ****************************************************\n",
    "\n",
    "countPSRNTot = test_Fail_all_EYFSPY1.groupby(['PSRNTotalFail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSRNTotalFail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSRNTotalFail':'Count'})\n",
    "#print(countCLLAS1)\n",
    "countPSRNTotPass = countPSRNTot.reset_index()\n",
    "countPSRNTotFail = countPSRNTot.reset_index()\n",
    "\n",
    "countPSRNTotPass['Domain'] = \"Solving , Numeracy Counting \"\n",
    "countPSRNTotFail['Domain'] = \"Solving , Numeracy Counting \"\n",
    "\n",
    "countPSRNTotFail = countPSRNTotFail[countPSRNTotFail['PSRNTotalFail'] == True].drop(['PSRNTotalFail'], axis=1)\n",
    "countPSRNTotPass = countPSRNTotPass[countPSRNTotPass['PSRNTotalFail'] == False].drop(['PSRNTotalFail'], axis=1)\n",
    "\n",
    "print(countPSRNTotPass)\n",
    "print(countPSRNTotFail)\n",
    "\n",
    "countPSRNAS1 = test_Fail_all_EYFSPY1.groupby(['PSRNAS1Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSRNAS1Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSRNAS1Fail':'Count'})\n",
    "#print(countPSRNAS1)\n",
    "\n",
    "countPSRNAS1Pass = countPSRNAS1.reset_index()\n",
    "countPSRNAS1Fail = countPSRNAS1.reset_index()\n",
    "\n",
    "countPSRNAS1Pass['Domain'] = \"Solving , Numeracy Counting PSRNAS1\"\n",
    "countPSRNAS1Fail['Domain'] = \"Solving , Numeracy Counting PSRNAS1\"\n",
    "\n",
    "countPSRNAS1Fail = countPSRNAS1Fail[countPSRNAS1Fail['PSRNAS1Fail'] == True].drop(['PSRNAS1Fail'], axis=1)\n",
    "countPSRNAS1Pass = countPSRNAS1Pass[countPSRNAS1Pass['PSRNAS1Fail'] == False].drop(['PSRNAS1Fail'], axis=1)\n",
    "\n",
    "print(countPSRNAS1Pass)\n",
    "print(countPSRNAS1Fail)\n",
    "\n",
    "# ***********\n",
    "# PSRNAS2\n",
    "# ***********\n",
    "\n",
    "countPSRNAS2 = test_Fail_all_EYFSPY1.groupby(['PSRNAS2Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSRNAS2Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSRNAS2Fail':'Count'})\n",
    "#print(countPSRNAS2)\n",
    "countPSRNAS2Pass = countPSRNAS2.reset_index()\n",
    "countPSRNAS2Fail = countPSRNAS2.reset_index()\n",
    "\n",
    "countPSRNAS2Pass['Domain'] = \"Solving , Numeracy Calculating PSRNAS2\"\n",
    "countPSRNAS2Fail['Domain'] = \"Solving , Numeracy Calculating PSRNAS2\"\n",
    "\n",
    "countPSRNAS2Fail = countPSRNAS2Fail[countPSRNAS2Fail['PSRNAS2Fail'] == True].drop(['PSRNAS2Fail'], axis=1)\n",
    "countPSRNAS2Pass = countPSRNAS2Pass[countPSRNAS2Pass['PSRNAS2Fail'] == False].drop(['PSRNAS2Fail'], axis=1)\n",
    "\n",
    "print(countPSRNAS2Pass)\n",
    "print(countPSRNAS2Fail)\n",
    "\n",
    "# ***********\n",
    "# PSRNAS3\n",
    "# ***********\n",
    "countPSRNAS3 = test_Fail_all_EYFSPY1.groupby(['PSRNAS3Fail']).agg({\n",
    "    #'newGLD':'count', \n",
    "    'PSRNAS3Fail':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'PSRNAS3Fail':'Count'})\n",
    "#print(countPSRNAS3)\n",
    "countPSRNAS3Pass = countPSRNAS3.reset_index()\n",
    "countPSRNAS3Fail = countPSRNAS3.reset_index()\n",
    "\n",
    "countPSRNAS3Pass['Domain'] = \"Solving , Numeracy Calculating PSRNAS3\"\n",
    "countPSRNAS3Fail['Domain'] = \"Solving , Numeracy Calculating PSRNAS3\"\n",
    "\n",
    "countPSRNAS3Fail = countPSRNAS3Fail[countPSRNAS3Fail['PSRNAS3Fail'] == True].drop(['PSRNAS3Fail'], axis=1)\n",
    "countPSRNAS3Pass = countPSRNAS3Pass[countPSRNAS3Pass['PSRNAS3Fail'] == False].drop(['PSRNAS3Fail'], axis=1)\n",
    "\n",
    "print(countPSRNAS3Pass)\n",
    "print(countPSRNAS3Fail)\n",
    "\n",
    "# 'countPSEAS1Pass','countPSEAS1Fail','countPSEAS2Pass','countPSEAS2Fail','countPSEAS3Pass','countPSEAS3Fail'\n",
    "# 'countCLLAS1Pass', 'countCLLAS1Fail','countCLLAS2Pass','countCLLAS2Fail','countCLLAS3Pass','countCLLAS3Fail','countCLLAS4Pass','countCLLAS4Fail'\n",
    "# 'countPSRNAS1Pass','countPSRNAS1Fail','countPSRNAS2Pass','countPSRNAS2Fail','countPSRNAS3Pass','countPSRNAS3Fail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7245f18-9404-4d2c-80e3-718434001631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ****************************************************\n",
    "# For All Understanding the world, Physical Development, Creative Development\n",
    "# ****************************************************\n",
    "count_RKUW = test_Fail_all_EYFSPY1.groupby(['RKUWFAIL']).agg({\n",
    "    'RKUWFAIL':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'RKUWFAIL':'Count'})\n",
    "countRKUWPass = count_RKUW.reset_index()\n",
    "countRKUWFail = count_RKUW.reset_index()\n",
    "\n",
    "countRKUWPass['Domain'] = \"Understanding of the World RKUW\"\n",
    "countRKUWFail['Domain'] = \"Understanding of the World RKUW\"\n",
    "\n",
    "countRKUWFail = countRKUWFail[countRKUWFail['RKUWFAIL'] == True].drop(['RKUWFAIL'], axis=1)\n",
    "countRKUWPass = countRKUWPass[countRKUWPass['RKUWFAIL'] == False].drop(['RKUWFAIL'], axis=1)\n",
    "\n",
    "# print(countRKUWPass)\n",
    "# print(countRKUWFail)\n",
    "\n",
    "# ***********\n",
    "# RICD\n",
    "# ***********\n",
    "\n",
    "count_RICD = test_Fail_all_EYFSPY1.groupby(['RICDFAIL']).agg({\n",
    "    'RICDFAIL':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'RICDFAIL':'Count'})\n",
    "# print(count_RKUW)\n",
    "\n",
    "countRICDPass = count_RICD.reset_index()\n",
    "countRICDFail = count_RICD.reset_index()\n",
    "\n",
    "countRICDPass['Domain'] = \"Creative Development RICD\"\n",
    "countRICDFail['Domain'] = \"Creative Development RICD\"\n",
    "\n",
    "countRICDFail = countRICDFail[countRICDFail['RICDFAIL'] == True].drop(['RICDFAIL'], axis=1)\n",
    "countRICDPass = countRICDPass[countRICDPass['RICDFAIL'] == False].drop(['RICDFAIL'], axis=1)\n",
    "\n",
    "# print(countRICDPass)\n",
    "# print(countRICDFail)\n",
    "\n",
    "# ***********\n",
    "# RIPD\n",
    "# ***********\n",
    "\n",
    "count_RIPD = test_Fail_all_EYFSPY1.groupby(['RIPDFAIL']).agg({\n",
    "    'RIPDFAIL':'count',\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum'}).rename(columns={'RIPDFAIL':'Count'})\n",
    "# print(count_RKUW)\n",
    "\n",
    "countRIPDPass = count_RIPD.reset_index()\n",
    "countRIPDFail = count_RIPD.reset_index()\n",
    "\n",
    "countRIPDPass['Domain'] = \"Physical Development RIPD\"\n",
    "countRIPDFail['Domain'] = \"Physical Development RIPD\"\n",
    "\n",
    "countRIPDFail = countRIPDFail[countRIPDFail['RIPDFAIL'] == True].drop(['RIPDFAIL'], axis=1)\n",
    "countRIPDPass = countRIPDPass[countRIPDPass['RIPDFAIL'] == False].drop(['RIPDFAIL'], axis=1)\n",
    "\n",
    "# print(countRIPDPass)\n",
    "# print(countRIPDFail)\n",
    "\n",
    "\n",
    "domainTotalPass = pd.concat([countCLLTotPass,countPSETotPass,countPSRNTotPass ])\n",
    "domainTotalFail = pd.concat([countCLLTotFail,countPSETotFail,countPSRNTotFail ])\n",
    "\n",
    "\n",
    "domainPassAll = pd.concat([countPSEAS1Pass,countPSEAS2Pass,countPSEAS3Pass,\n",
    "                           countCLLAS1Pass,countCLLAS2Pass,countCLLAS3Pass,\n",
    "                           countCLLAS4Pass,countPSRNAS1Pass,countPSRNAS2Pass,\n",
    "                           countPSRNAS3Pass,countRKUWPass,countRICDPass,countRIPDPass])\n",
    "\n",
    "domainFailAll = pd.concat([countPSEAS1Fail,countPSEAS2Fail,countPSEAS3Fail,countCLLAS1Fail,\n",
    "                           countCLLAS2Fail,countCLLAS3Fail,countCLLAS4Fail,countPSRNAS1Fail,\n",
    "                           countPSRNAS2Fail,countPSRNAS3Fail,countRKUWFail,countRICDFail,countRIPDFail])\n",
    "\n",
    "domainTotalPass['CT_PCT']=(domainTotalPass['Count']/8240)*100\n",
    "domainTotalPass['EverNEET_PCT']=(domainTotalPass['ever_NEET']/domainTotalPass['Count'])*100\n",
    "domainTotalPass['PNEET_PCT']=(domainTotalPass['Persistent_NEET']/domainTotalPass['Count'])*100\n",
    "\n",
    "\n",
    "domainTotalFail['CT_PCT1']=(domainTotalFail['Count']/8240)*100\n",
    "domainTotalFail['EverNEET_PCT1']=(domainTotalFail['ever_NEET']/domainTotalFail['Count'])*100\n",
    "domainTotalFail['PNEET_PCT1']=(domainTotalFail['Persistent_NEET']/domainTotalFail['Count'])*100\n",
    "domainTotalFail = domainTotalFail.rename(columns={'Count':'Count1','ever_NEET':'ever_NEET1', 'Persistent_NEET':'Persistent_NEET1'})\n",
    "\n",
    "\n",
    "domainPassAll['CT_PCT']=(domainPassAll['Count']/8240)*100\n",
    "domainPassAll['EverNEET_PCT']=(domainPassAll['ever_NEET']/domainPassAll['Count'])*100\n",
    "domainPassAll['PNEET_PCT']=(domainPassAll['Persistent_NEET']/domainPassAll['Count'])*100\n",
    "\n",
    "domainFailAll['CT_PCT1']=(domainFailAll['Count']/8240)*100\n",
    "domainFailAll['EverNEET_PCT1']=(domainFailAll['ever_NEET']/domainFailAll['Count'])*100\n",
    "domainFailAll['PNEET_PCT1']=(domainFailAll['Persistent_NEET']/domainFailAll['Count'])*100\n",
    "\n",
    "domainFailAll = domainFailAll.rename(columns={'Count':'Count1','ever_NEET':'ever_NEET1', 'Persistent_NEET':'Persistent_NEET1'\n",
    "                             })\n",
    "NEETDF = pd.merge(domainPassAll, domainFailAll, on='Domain',how='left')\n",
    "\n",
    "NEETtotDF = pd.merge(domainTotalPass, domainTotalFail, on='Domain',how='left')\n",
    "\n",
    "\n",
    "# print(domainTotalPass)\n",
    "# print(domainTotalFail)\n",
    "\n",
    "# print(\"Passed stats\",domainPassAll)\n",
    "# print(\"Failed stats\",domainFailAll)\n",
    "# print(NEETDF)\n",
    "print(NEETtotDF)                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2fa45-8503-4ea2-bbea-4e59805464db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "totordered_df = NEETtotDF.sort_values(by='EverNEET_PCT')\n",
    "my_range=range(1,len(NEETtotDF.index)+1)\n",
    "\n",
    "plt.hlines(y=my_range, xmin=totordered_df['EverNEET_PCT'], xmax=totordered_df['EverNEET_PCT1'], color='grey', alpha=0.6)\n",
    "# plt.scatter(ordered_df['CT_PCT'], my_range, color='skyblue', alpha=1, label='Failed Count %')\n",
    "plt.scatter(totordered_df['EverNEET_PCT1'], my_range, color='orange', alpha=0.6 , label='ENEET F Domain')\n",
    "plt.scatter(totordered_df['EverNEET_PCT'], my_range, color='purple', alpha=0.6 , label='ENEET P Domain')\n",
    "\n",
    "# legend = ax.legend(loc='lower right')\n",
    "plt.legend(loc='center')\n",
    "\n",
    "# Add title and axis names\n",
    "plt.yticks(my_range, totordered_df['Domain'])\n",
    "plt.title(\"Comparision of NEET when failed the domain to have passed the domain \", loc='left')\n",
    "plt.xlabel('% Ever NEET')\n",
    "plt.ylabel('Domain')\n",
    "\n",
    "# y axis is categorical. Create a map between categories and Matplotlib\n",
    "# numerical values on the y axis.\n",
    "yticks_dict = {k: v for k, v in zip(totordered_df['EverNEET_PCT1'], plt.yticks()[0])}\n",
    "# use a small offset to place the annotation slightly above the\n",
    "# categorical value\n",
    "offset = 0.05\n",
    "for x, y in zip(totordered_df['EverNEET_PCT'], totordered_df['EverNEET_PCT1']):\n",
    "    plt.text(x, yticks_dict[y] + offset, round(x, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "    plt.text(y, yticks_dict[y] + offset, round(y, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "\n",
    "# set the ylim if necessary\n",
    "new_offset = 5 * offset\n",
    "plt.ylim(min(yticks_dict.values()) - new_offset, max(yticks_dict.values()) + new_offset)\n",
    "    \n",
    "# # Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b75a13-0ca5-465c-9d89-f9cbb87536e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "totordered_df1 = NEETtotDF.sort_values(by='PNEET_PCT1')\n",
    "my_range1=range(1,len(NEETtotDF.index)+1)\n",
    "\n",
    "plt.hlines(y=my_range1, xmin=totordered_df1['PNEET_PCT'], xmax=totordered_df1['PNEET_PCT1'], color='grey', alpha=0.4)\n",
    "# plt.scatter(ordered_df1['CT_PCT'], my_range1, color='skyblue', alpha=1, label='Passed Count %')\n",
    "plt.scatter(totordered_df1['PNEET_PCT1'], my_range1, color='green', alpha=0.4 , label='P NEET F Domain')\n",
    "plt.scatter(totordered_df1['PNEET_PCT'], my_range1, color='red', alpha=0.4 , label='P NEET  P Domain')\n",
    "plt.legend(loc='center')\n",
    "\n",
    "# Add title and axis names\n",
    "plt.yticks(my_range1, totordered_df1['Domain'])\n",
    "plt.title(\"Comparision of PNEET when failed the domain to have passed the domain \", loc='left')\n",
    "plt.xlabel('% Persistent NEET')\n",
    "plt.ylabel('Domain')\n",
    "\n",
    "# y axis is categorical. Create a map between categories and Matplotlib\n",
    "# numerical values on the y axis.\n",
    "yticks_dict = {k: v for k, v in zip(totordered_df1['PNEET_PCT1'], plt.yticks()[0])}\n",
    "# use a small offset to place the annotation slightly above the\n",
    "# categorical value\n",
    "offset = 0.05\n",
    "for x, y in zip(totordered_df1['PNEET_PCT'], totordered_df1['PNEET_PCT1']):\n",
    "    plt.text(x, yticks_dict[y] + offset, round(x, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "    plt.text(y, yticks_dict[y] + offset, round(y, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "# set the ylim if necessary\n",
    "new_offset = 5 * offset\n",
    "plt.ylim(min(yticks_dict.values()) - new_offset, max(yticks_dict.values()) + new_offset)\n",
    "    \n",
    "# # Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51915eab-cc81-4d36-bc20-7550af28f659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_df = NEETDF.sort_values(by='EverNEET_PCT')\n",
    "my_range=range(1,len(NEETDF.index)+1)\n",
    "\n",
    "plt.hlines(y=my_range, xmin=ordered_df['EverNEET_PCT'], xmax=ordered_df['EverNEET_PCT1'], color='pink', alpha=0.6)\n",
    "# plt.scatter(ordered_df['CT_PCT'], my_range, color='skyblue', alpha=1, label='Failed Count %')\n",
    "plt.scatter(ordered_df['EverNEET_PCT1'], my_range, color='red', alpha=0.6 , label='ENEET F Domain')\n",
    "plt.scatter(ordered_df['EverNEET_PCT'], my_range, color='blue', alpha=0.6 , label='ENEET P Domain')\n",
    "\n",
    "# legend = ax.legend(loc='lower right')\n",
    "plt.legend(loc='center')\n",
    "\n",
    "# Add title and axis names\n",
    "plt.yticks(my_range, ordered_df['Domain'])\n",
    "plt.title(\"Comparision of NEET when failed the domain to have passed the domain \", loc='left')\n",
    "plt.xlabel('% Ever NEET')\n",
    "plt.ylabel('Domain')\n",
    "\n",
    "# y axis is categorical. Create a map between categories and Matplotlib\n",
    "# numerical values on the y axis.\n",
    "yticks_dict = {k: v for k, v in zip(ordered_df['EverNEET_PCT1'], plt.yticks()[0])}\n",
    "# use a small offset to place the annotation slightly above the\n",
    "# categorical value\n",
    "offset = 0.05\n",
    "for x, y in zip(ordered_df['EverNEET_PCT'], ordered_df['EverNEET_PCT1']):\n",
    "    plt.text(x, yticks_dict[y] + offset, round(x, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "    plt.text(y, yticks_dict[y] + offset, round(y, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "\n",
    "# set the ylim if necessary\n",
    "new_offset = 5 * offset\n",
    "plt.ylim(min(yticks_dict.values()) - new_offset, max(yticks_dict.values()) + new_offset)\n",
    "    \n",
    "# # Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87374af-5691-4482-bccd-87cedd578065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_df1 = NEETDF.sort_values(by='PNEET_PCT')\n",
    "my_range1=range(1,len(NEETDF.index)+1)\n",
    "\n",
    "plt.hlines(y=my_range1, xmin=ordered_df1['PNEET_PCT'], xmax=ordered_df1['PNEET_PCT1'], color='pink', alpha=0.6)\n",
    "# plt.scatter(ordered_df1['CT_PCT'], my_range1, color='skyblue', alpha=1, label='Passed Count %')\n",
    "plt.scatter(ordered_df1['PNEET_PCT1'], my_range1, color='green', alpha=0.6 , label='P NEET F Domain')\n",
    "plt.scatter(ordered_df1['PNEET_PCT'], my_range1, color='red', alpha=0.6 , label='P NEET  P Domain')\n",
    "plt.legend(loc='center')\n",
    "\n",
    "# Add title and axis names\n",
    "plt.yticks(my_range1, ordered_df1['Domain'])\n",
    "plt.title(\"Comparision of PNEET when failed the domain to have passed the domain \", loc='left')\n",
    "plt.xlabel('% Persistent NEET')\n",
    "plt.ylabel('Domain')\n",
    "\n",
    "# y axis is categorical. Create a map between categories and Matplotlib\n",
    "# numerical values on the y axis.\n",
    "yticks_dict = {k: v for k, v in zip(ordered_df1['PNEET_PCT1'], plt.yticks()[0])}\n",
    "# use a small offset to place the annotation slightly above the\n",
    "# categorical value\n",
    "offset = 0.05\n",
    "for x, y in zip(ordered_df1['PNEET_PCT'], ordered_df1['PNEET_PCT1']):\n",
    "    plt.text(x, yticks_dict[y] + offset, round(x, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "    plt.text(y, yticks_dict[y] + offset, round(y, 2), horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "# set the ylim if necessary\n",
    "new_offset = 5 * offset\n",
    "plt.ylim(min(yticks_dict.values()) - new_offset, max(yticks_dict.values()) + new_offset)\n",
    "    \n",
    "# # Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9f7e3-9dfa-4620-a112-3bdf5ac6f881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the data for 'EverNEET_PCT' and 'EverNEET_PCT1'\n",
    "\n",
    "# Calculate the difference for each domain\n",
    "difference = ordered_df['EverNEET_PCT1'] - ordered_df['EverNEET_PCT']\n",
    "\n",
    "# Create a horizontal line plot for the difference\n",
    "plt.hlines(y=my_range, xmin=0, xmax=difference, color='green', alpha=0.7, label='Diff (E NEET Failed - E NEET Passed)')\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.yticks(my_range, ordered_df['Domain'])\n",
    "plt.title(\"% Difference in NEET chances when failing or passing the domain\", loc='left')\n",
    "plt.xlabel('Difference in Percentage')\n",
    "plt.ylabel('Domain')\n",
    "\n",
    "# Legend and plot display\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933a80e-669a-417e-8aeb-6d01f51caa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the data for 'EverNEET_PCT' and 'EverNEET_PCT1'\n",
    "\n",
    "# Calculate the difference for each domain\n",
    "difference = ordered_df['PNEET_PCT1'] - ordered_df['PNEET_PCT']\n",
    "\n",
    "# Create a horizontal line plot for the difference\n",
    "plt.hlines(y=my_range, xmin=0, xmax=difference, color='purple', alpha=0.7, label='Diff (Persistent NEET Failed - Persistent NEET Passed)')\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.yticks(my_range, ordered_df['Domain'])\n",
    "plt.title(\"% Difference in P NEET chances when failing or passing the domain\", loc='left')\n",
    "plt.xlabel('Difference in Percentage Persistent NEET')\n",
    "plt.ylabel('Domain')\n",
    "\n",
    "# Legend and plot display\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34597fdd-d204-444d-bd22-a6e5b47fb19b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bar plot to visualise the % of student who failed that domain who became ever-neet / Persistent Neet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dad7cf-97cf-45eb-a82b-58aad8f44ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rfs = FailAllStats.drop(['AcademicYear'],axis=1)\n",
    "domainFailAll=domainFailAll.sort_values('CT_PCT1')\n",
    "rfs1 = pd.melt(domainFailAll.drop(['Count1','ever_NEET1','Persistent_NEET1'],axis=1), id_vars = \"Domain\")\n",
    "rfs1 = rfs1.rename(columns={\"variable\": \"Statistics\"})\n",
    "\n",
    "#print(rfs1)\n",
    "# fig, ax = plt.subplots(figsize=(17, 10))\n",
    "# fig.patch.set_visible(False)\n",
    "\n",
    "g=sns.catplot(x = 'Domain', y='value',hue = 'Statistics',data=rfs1, kind='bar', width = 1, legend=True, height=6, aspect=2, palette = 'pastel')\n",
    "ax = g.facet_axis(0, 0)  # or ax = g.axes.flat[0]\n",
    "\n",
    "# iterate through the axes containers\n",
    "for c in ax.containers:\n",
    "    labels = [f'{(v.get_height() ):.1f}' for v in c]\n",
    "    ax.bar_label(c, labels=labels, label_type='edge')\n",
    "#sns.despine()\n",
    "plt.title(\"Domain wise % NEET / % Persistent NEET\")\n",
    "plt.xlabel(\"Distribution of doaminwise failure to NEET %\")\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559c008-3c39-429e-94ee-3abfaf0548ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "domainPassAll=domainPassAll.sort_values('CT_PCT')\n",
    "tfs1 = pd.melt(domainPassAll.drop(['Count','ever_NEET','Persistent_NEET'],axis=1), id_vars = \"Domain\")\n",
    "\n",
    "#dfs1\n",
    "tfs1 = tfs1.rename(columns={\"variable\": \"Statistics\"})\n",
    "\n",
    "g=sns.catplot(x = 'Domain', y='value',hue = 'Statistics',data=tfs1, kind='bar', width = 1, legend=True, height=6, aspect=2)\n",
    "ax = g.facet_axis(0, 0)  # or ax = g.axes.flat[0]\n",
    "\n",
    "# iterate through the axes containers\n",
    "for c in ax.containers:\n",
    "    labels = [f'{(v.get_height() ):.1f}' for v in c]\n",
    "    ax.bar_label(c, labels=labels, label_type='edge')\n",
    "#sns.despine()\n",
    "plt.title(\"Domain wise passing moving onto becoming  NEET\")\n",
    "plt.xlabel(\"Domain wise and NEET &\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e5934-5682-43b7-95d9-ad0b48b6d5ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling to Predict GLD to NEET Status\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<h1> Predicting GLD to NEET Status </h1>\n",
    "<h3> Performing Generalised Linear Regression </h3>\n",
    "\n",
    "\n",
    "<h3>    Adding other covariates to understand the Statistically significant values</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5adbba-a24d-4ee9-baf9-87dda26a24d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "modelDF = statutaryYears2006_2009\n",
    "\n",
    "ct=pd.crosstab(modelDF.ever_NEET,modelDF.newGLD)\n",
    "oddsratio, pvalue = stats.fisher_exact(ct)\n",
    "print(\"odds Ratio, pValue\",np.asarray((oddsratio, pvalue)))\n",
    "\n",
    "# modelDF['newGLD'] = modelDF['newGLD'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "modelDF['ever_NEET'] = modelDF['ever_NEET'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "\n",
    "# Splitting the data into 2 parts\n",
    "# train, test = np.split(\n",
    "#     modelDF.sample(frac=1, random_state=42), [int(0.8 * len(modelDF))]\n",
    "# )\n",
    "\n",
    "print(modelDF.ever_NEET.sum())\n",
    "print(len(modelDF.ever_NEET))\n",
    "\n",
    "\n",
    "model = sm.formula.glm(\"ever_NEET ~ C(newGLD, Treatment(reference=False))\",\n",
    "                       family=sm.families.Binomial(), data=modelDF).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "predictions=model.predict()\n",
    "print(type(predictions))\n",
    "print(np.unique(predictions))\n",
    "\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "print(np.unique(modelDF['ever_NEET']))\n",
    "\n",
    "uniqueT, countsT = np.unique(modelDF['ever_NEET'], return_counts=True)\n",
    "\n",
    "print(np.asarray((uniqueT, countsT)).T)\n",
    "\n",
    "predictions_nominal = [1 if x < 0.1 else 0 for x in predictions]\n",
    "      \n",
    "print(model.params.Intercept)\n",
    "odds_ratio=np.exp(model.params.Intercept)\n",
    "print('odds ratio is ',odds_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55887da9-0c69-45b2-a546-f4f39dd40755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cnf_matrix = confusion_matrix(modelDF[\"ever_NEET\"], \n",
    "                       predictions_nominal)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(classification_report(modelDF[\"ever_NEET\"], \n",
    "                            predictions_nominal, \n",
    "                            digits = 3))\n",
    "\n",
    "class_names=[\"0\",\"1\"] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label NEET')\n",
    "plt.xlabel('Predicted label NEET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee198e-546f-4b91-92ce-1484b5abd35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelDF = statutaryYears2006_2009\n",
    "\n",
    "\n",
    "# print(modelDF.ever_NEET.sum())\n",
    "# print(len(modelDF.ever_NEET))\n",
    "\n",
    "# model_covariates = sm.formula.glm(\"ever_NEET ~ C(newGLD+CLLAS1, Treatment(reference=True))\",\n",
    "#                        family=sm.families.Binomial(), data=modelDF).fit()\n",
    "\n",
    "# print(model_covariates.summary())\n",
    "# predictionsCovarites=model_covariates.predict()\n",
    "\n",
    "# print(np.unique(predictionsCovarites))\n",
    "\n",
    "# unique, counts = np.unique(predictionsCovarites, return_counts=True)\n",
    "\n",
    "# print(np.asarray((unique, counts)).T)\n",
    "\n",
    "# uniqueT, countsT = np.unique(modelDF['ever_NEET'], return_counts=True)\n",
    "\n",
    "# print(np.asarray((uniqueT, countsT)).T)\n",
    "\n",
    "# predictions_Covarites = [1 if x < 0.069 else 0 for x in predictionsCovarites]\n",
    "# print(model_covariates.params.Intercept)\n",
    "# odds_ratio_covariates=np.exp(model_covariates.params.Intercept)\n",
    "# print('odds ratio is ',odds_ratio_covariates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76752adb-8515-4118-8f2f-4ebc1c33eaa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnf_matrix_Covarites = confusion_matrix(modelDF[\"ever_NEET\"], \n",
    "#                        predictions_Covarites)\n",
    "# print(cnf_matrix_Covarites)\n",
    "\n",
    "# print(classification_report(modelDF[\"ever_NEET\"], \n",
    "#                             predictions_Covarites, \n",
    "#                             digits = 3))\n",
    "\n",
    "# class_names=[\"0\",\"1\"] # name  of classes\n",
    "# fig, ax = plt.subplots()\n",
    "# tick_marks = np.arange(len(class_names))\n",
    "# plt.xticks(tick_marks, class_names)\n",
    "# plt.yticks(tick_marks, class_names)\n",
    "# # create heatmap\n",
    "# sns.heatmap(pd.DataFrame(cnf_matrix_Covarites), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "# plt.tight_layout()\n",
    "# plt.title('Confusion matrix', y=1.1)\n",
    "# plt.ylabel('Actual label NEET')\n",
    "# plt.xlabel('Predicted label NEET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518739fb-e847-4366-b649-8630e057602d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "modelDF = statutaryYears2006_2009\n",
    "\n",
    "ct=pd.crosstab(modelDF.ever_NEET,modelDF.newGLD)\n",
    "oddsratio, pvalue = stats.fisher_exact(ct)\n",
    "print(\"odds Ratio, pValue\",np.asarray((oddsratio, pvalue)))\n",
    "\n",
    "# modelDF['newGLD'] = modelDF['newGLD'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "modelDF['ever_NEET'] = modelDF['ever_NEET'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "\n",
    "# Splitting the data into 2 parts\n",
    "# train, test = np.split(\n",
    "#     modelDF.sample(frac=1, random_state=42), [int(0.8 * len(modelDF))]\n",
    "# )\n",
    "\n",
    "print(modelDF.ever_NEET.sum())\n",
    "print(len(modelDF.ever_NEET))\n",
    "\n",
    "\n",
    "model = sm.formula.glm(\"ever_NEET ~ C(newGLD, Treatment(reference=False))\",\n",
    "                       family=sm.families.Binomial(), data=modelDF).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "predictions=model.predict()\n",
    "print(type(predictions))\n",
    "print(np.unique(predictions))\n",
    "\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "print(np.unique(modelDF['ever_NEET']))\n",
    "\n",
    "uniqueT, countsT = np.unique(modelDF['ever_NEET'], return_counts=True)\n",
    "\n",
    "print(np.asarray((uniqueT, countsT)).T)\n",
    "\n",
    "predictions_nominal = [1 if x < 0.1 else 0 for x in predictions]\n",
    "      \n",
    "print(model.params.Intercept)\n",
    "odds_ratio=np.exp(model.params.Intercept)\n",
    "print('odds ratio is ',odds_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00accb-0d51-435d-b367-e86baeb94b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cnf_matrix = confusion_matrix(modelDF[\"ever_NEET\"], \n",
    "                       predictions_nominal)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(classification_report(modelDF[\"ever_NEET\"], \n",
    "                            predictions_nominal, \n",
    "                            digits = 3))\n",
    "\n",
    "class_names=[\"0\",\"1\"] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label NEET')\n",
    "plt.xlabel('Predicted label NEET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42166cb9-6836-421e-abda-0179d0d8c1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelDF = statutaryYears2006_2009\n",
    "\n",
    "\n",
    "# print(modelDF.ever_NEET.sum())\n",
    "# print(len(modelDF.ever_NEET))\n",
    "\n",
    "# model_covariates = sm.formula.glm(\"ever_NEET ~ C(newGLD+CLLAS1, Treatment(reference=True))\",\n",
    "#                        family=sm.families.Binomial(), data=modelDF).fit()\n",
    "\n",
    "# print(model_covariates.summary())\n",
    "# predictionsCovarites=model_covariates.predict()\n",
    "\n",
    "# print(np.unique(predictionsCovarites))\n",
    "\n",
    "# unique, counts = np.unique(predictionsCovarites, return_counts=True)\n",
    "\n",
    "# print(np.asarray((unique, counts)).T)\n",
    "\n",
    "# uniqueT, countsT = np.unique(modelDF['ever_NEET'], return_counts=True)\n",
    "\n",
    "# print(np.asarray((uniqueT, countsT)).T)\n",
    "\n",
    "# predictions_Covarites = [1 if x < 0.069 else 0 for x in predictionsCovarites]\n",
    "# print(model_covariates.params.Intercept)\n",
    "# odds_ratio_covariates=np.exp(model_covariates.params.Intercept)\n",
    "# print('odds ratio is ',odds_ratio_covariates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c8107-827a-4bae-b133-2d4a919c778f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnf_matrix_Covarites = confusion_matrix(modelDF[\"ever_NEET\"], \n",
    "#                        predictions_Covarites)\n",
    "# print(cnf_matrix_Covarites)\n",
    "\n",
    "# print(classification_report(modelDF[\"ever_NEET\"], \n",
    "#                             predictions_Covarites, \n",
    "#                             digits = 3))\n",
    "\n",
    "# class_names=[\"0\",\"1\"] # name  of classes\n",
    "# fig, ax = plt.subplots()\n",
    "# tick_marks = np.arange(len(class_names))\n",
    "# plt.xticks(tick_marks, class_names)\n",
    "# plt.yticks(tick_marks, class_names)\n",
    "# # create heatmap\n",
    "# sns.heatmap(pd.DataFrame(cnf_matrix_Covarites), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "# plt.tight_layout()\n",
    "# plt.title('Confusion matrix', y=1.1)\n",
    "# plt.ylabel('Actual label NEET')\n",
    "# plt.xlabel('Predicted label NEET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0d6e5-4ef2-4684-a272-6a08e6dd555e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetching Covariates \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<h3> To understand the predictive power of becoming NEET from other covariates like free school meal disability flag, SEND flag</h3>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb2afc-64ad-4d91-a599-30afbf8c0168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "personUniqueID = statutaryYears2006_2009[\"person_id\"].unique()\n",
    "ct=len(personUniqueID)\n",
    "ct\n",
    "#8240 unique ids\n",
    "#pID = map(str, personUniqueID) \n",
    "Pid = tuple(personUniqueID)\n",
    "\n",
    "# sqlWideFormat1 = \"\"\" SELECT person_id, GRADE FROM `yhcr-prd-phm-bia-core.CB_FDM_DepartmentForEducation.src_KS4_exam` WHERE person_id IN {} order by person_id\"\"\".format(Pid)\n",
    "\n",
    "sqlWideFormat1 = \"\"\" SELECT a.person_id,a.LSOA, a.AgeAtStartOfAcademicYear,a.FSMEligible,a.EverFSM6,a.EverFSM6P,a.EverFSMAll,\n",
    "                                        a.EYPPE,a.EYPPBF,a.EYUEntitlement,\n",
    "                                        a.EYEEntitlement,a.PPEntitlement,a.SBEntitlement, b.LDDFlag, b.SENDFlag , a.language,\n",
    "                                        a.InCare, a.InCareAtCurrentSchool, a.NSiblings, a.birthorder FROM \n",
    "                                        `yhcr-prd-phm-bia-core.CB_FDM_DepartmentForEducation.src_census` a, \n",
    "                                        `yhcr-prd-phm-bia-core.CB_FDM_DepartmentForEducation.src_NCCIS` b\n",
    "                                        WHERE a.person_id=b.person_id and b.person_id IN {} order by a.person_id, a.CensusDate\"\"\".format(Pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254e495-8fba-4896-874d-c0fc5a1c0955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tableDBWideFormat1 = pdg.read_gbq(sqlWideFormat1, dialect='standard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8d7c4-ffdf-41c7-85c9-b28c67d1cd8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tableDBWideFormat1.person_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1f961-4bc7-4175-8b9b-f1743c33891e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 8231 students records fetched from census table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007687c1-e2a8-453b-b88b-6fb1124c987c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "censusRecordsNEET = tableDBWideFormat1[[\"person_id\",\"LSOA\",\"AgeAtStartOfAcademicYear\",\"FSMEligible\",\"EverFSM6\",\"EverFSM6P\",\"EverFSMAll\",\n",
    "                                        \"EYPPE\",\"EYPPBF\",\"EYUEntitlement\",\n",
    "                                        \"EYEEntitlement\",\"PPEntitlement\",\"SBEntitlement\",\"LDDFlag\",\"SENDFlag\",\"language\", \n",
    "                                        \"InCare\",\"InCareAtCurrentSchool\",\"NSiblings\",\"birthorder\" ]]\n",
    "censusRecordsNEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd11e4-1aa2-4ad4-8971-6deaba923517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "censusRecordsNEET[\"FreeSchoolMeal\"] = censusRecordsNEET.groupby('person_id').EverFSM6.transform('max') | censusRecordsNEET.EverFSM6P | censusRecordsNEET.EverFSMAll\n",
    "\n",
    "censusRecordsNEET[\"EntitlementFlag\"] = censusRecordsNEET.groupby('person_id').EYUEntitlement.transform('any') | censusRecordsNEET.EYEEntitlement | censusRecordsNEET.PPEntitlement | censusRecordsNEET.SBEntitlement\n",
    "censusRecordsNEET[\"LDDFlag\"] = censusRecordsNEET['LDDFlag'].apply(lambda set_: False if pd.isna(set_)== True else True)\n",
    "censusRecordsNEET[\"SENDFlag\"] = censusRecordsNEET['SENDFlag'].apply(lambda set_: False if ((pd.isna(set_)== True) | ((set_)=='N')) else True)\n",
    "\n",
    "censusRecordsNEET[\"language\"] = censusRecordsNEET.groupby('person_id').language.transform(mode) \n",
    "censusRecordsNEET[\"LDDFlag\"] = censusRecordsNEET['LDDFlag'].apply(lambda set_: False if pd.isna(set_)== True else True)\n",
    "\n",
    "censusRecordNEETDF = censusRecordsNEET[[\"person_id\",\"LSOA\",\"AgeAtStartOfAcademicYear\",\"FSMEligible\",\"FreeSchoolMeal\",\"EntitlementFlag\", \"LDDFlag\",\"SENDFlag\",\"language\",\n",
    "                                        \"InCare\",\"InCareAtCurrentSchool\",\"NSiblings\",\"birthorder\"]]\n",
    "\n",
    "#censusRecordNEETDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078893f-2c9c-4d35-a3f9-eddb234e47e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "censusRecordsNEETLSOA15GP = censusRecordsNEET.query(\"AgeAtStartOfAcademicYear == 15\").groupby([\"person_id\"]).agg({\n",
    "        'LSOA':lambda x: x.dropna().tail(1),\n",
    "        'FSMEligible': 'max', \n",
    "        'FreeSchoolMeal': 'max', \n",
    "    #    'EntitlementFlag': lambda x: x.dropna().tail(1)\n",
    "        'EntitlementFlag': 'max',\n",
    "        'LDDFlag':'max',\n",
    "        'SENDFlag':'max',\n",
    "        'language':mode,\n",
    "        'InCare':mode,\n",
    "        'InCareAtCurrentSchool':mode,\n",
    "        'NSiblings':mode,\n",
    "        'birthorder':mode\n",
    "    })\n",
    "\n",
    "censusRecordsNEETLSOA15GP=censusRecordsNEETLSOA15GP.reset_index()\n",
    "#censusRecordsNEETLSOA15GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2355db-1b3c-4744-b8fd-05f2446bb4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#peopleWithLSOA15 = censusRecordsNEETLSOA15GP[(censusRecordsNEETLSOA15GP[\"LSOA\"]!='[]')]\n",
    "#peopleWithLSOA15\n",
    "#peopleWithLSOA15 = censusRecordsNEETLSOA15GP\n",
    "\n",
    "LSOAUniq = censusRecordsNEETLSOA15GP['LSOA'].apply(lambda x: str(x))\n",
    "censusRecordsNEETLSOA15GP['LSOA']= censusRecordsNEETLSOA15GP['LSOA'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d048f2f-595f-49fe-a9da-b793688b51d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSOA_subset_codes = tuple(LSOAUniq)\n",
    "#LSOA_subset_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6303126-28b2-4286-ac01-bd2fb78eaa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY_BY_LSOA_SUBSET =  \"\"\" SELECT a.LSOA_code as LSOA, a.LSOA_name, b.ward_name, a.geometry as geometry_home, \n",
    "a.lat_long FROM `yhcr-prd-phm-bia-core.CB_LOOKUPS.tbl_lsoa_boundaries` a,`yhcr-prd-phm-bia-core.CB_LOOKUPS.tbl_bradford_map_prep` b WHERE a.LSOA_code = b.LSOA_code and a.LSOA_code IN {}\"\"\".format(LSOA_subset_codes[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be7dfb-d0d6-4738-98d5-b940a2c5ffc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tableLSOA = pdg.read_gbq(QUERY_BY_LSOA_SUBSET, dialect='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db805b-6f00-4b91-ae84-2832194f9f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GraphingGLDwithLSOA = pd.merge(censusRecordsNEETLSOA15GP,tableLSOA,on='LSOA',how='left')\n",
    "#GraphingGLDwithLSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6536232-4465-4a35-a9a5-79437ede0a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fec995-a09b-43c1-9220-9d94f97234b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DFafterMerge = pd.merge(modelDF,GraphingGLDwithLSOA,on='person_id',how='left')\n",
    "DFafterMerge = DFafterMerge.rename(columns={'Persistent_NEET_YN_over_4months':'Persistent_NEET'})\n",
    "#DFafterMerge.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cec83b-d6d2-4c86-98c6-a8673e112301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DFafterMerge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f8010-9984-4199-86ff-5ecd52ff3164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DFafterMerge['FreeSchoolMeal'] = DFafterMerge['FreeSchoolMeal'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "DFafterMerge['LDDFlag'] = DFafterMerge['LDDFlag'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "DFafterMerge['SENDFlag'] = DFafterMerge['SENDFlag'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "DFafterMerge['InCare'] = DFafterMerge['InCare'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "DFafterMerge['InCareAtCurrentSchool'] = DFafterMerge['InCareAtCurrentSchool'].apply(lambda set_: False if pd.isna(set_)== True else set_)\n",
    "DFafterMerge = DFafterMerge.rename(columns={'LSOA_y':'LSOA','LSOA_name_y':'LSOA_name','lat_long_y':'lat_long'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7bde5c-82c0-450c-89f9-52accea5b6db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "Flag1DataLSOA = DFafterMerge.groupby(['AcademicYear','newGLD','Gender']).agg({\n",
    "    'Gender':'value_counts',\n",
    "    'ever_NEET': lambda x: (x==False).sum(),\n",
    "    #'Persistent_NEET':'sum',\n",
    "    'Bradford_YN':'sum',\n",
    "    'FreeSchoolMeal':'sum',\n",
    "    #'LDDFlag':'sum',\n",
    "    'SENDFlag': lambda x: (x==True).sum(),\n",
    "    'language': mode,\n",
    "    'InCare': lambda x: (x==True).sum(),\n",
    "    'InCareAtCurrentSchool': lambda x: (x==True).sum(),\n",
    "    'NSiblings':mode,\n",
    "    'birthorder':mode\n",
    "    #'newGLD':'value_counts',\n",
    "     }).rename(columns={'Gender':'COUNTByGender', 'ever_NEET':'Non NEET'})\n",
    "Flag1DataLSOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51235d04-40fb-4063-9e57-f1b9b200a4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "FlagDataLSOA = DFafterMerge.groupby(['AcademicYear','newGLD','Gender']).agg({\n",
    "    'Gender':'value_counts',\n",
    "    'ever_NEET': lambda x: (x==True).sum(),\n",
    "    #'Persistent_NEET':'sum',\n",
    "    'Bradford_YN':'sum',\n",
    "    'FreeSchoolMeal':'sum',\n",
    "    #'LDDFlag':'sum',\n",
    "    'SENDFlag': lambda x: (x==True).sum(),\n",
    "    'language': mode,\n",
    "    'InCare': lambda x: (x==True).sum()\n",
    "    #'newGLD':'value_counts',\n",
    "     }).rename(columns={'Gender':'COUNTByGender', 'ever_NEET':'Ever NEET'})\n",
    "FlagDataLSOA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23fe3d0-d2a5-437b-a31e-68b61073e357",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stats of GLD non attainment based out of Bradford LSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88996af-14f0-484e-ad1c-54f4b9dc3e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FlagDataLSOA = FlagDataLSOA.reset_index()\n",
    "GLDTrueGenderFlagLSOA = FlagDataLSOA[(FlagDataLSOA['newGLD']==True)]\n",
    "GLDFalseGenderFlagLSOA = FlagDataLSOA[(FlagDataLSOA['newGLD']==False)]\n",
    "GLDTrueGenderFlagLSOA = GLDTrueGenderFlagLSOA.set_index(['AcademicYear','Gender'])\n",
    "#print(GLDTrueGenderFlagLSOA)\n",
    "GLDFalseGenderFlagLSOA = GLDFalseGenderFlagLSOA.set_index(['AcademicYear','Gender'])\n",
    "#print(GLDFalseGenderFlagLSOA)\n",
    "\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GLDFalseGenderFlagLSOA.drop(GLDFalseGenderFlagLSOA.tail(2).index,\n",
    "        inplace = True)\n",
    "\n",
    "fx=GLDFalseGenderFlagLSOA.plot(kind='bar')\n",
    "plt.ylabel('Count of people from Bradford LSOA')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "plt.gca().xaxis.set_tick_params(rotation=0)\n",
    "\n",
    "for bar in fx.patches:\n",
    "    height = bar.get_height()\n",
    "    fx.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    fx.set_title(\"count of GLD non attainment based out of Bradford LSOA\")\n",
    "\n",
    "plt.legend(loc='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182d591-ce35-4486-a3bc-7fd1825881e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "GLD_LSOA_format = DFafterMerge.groupby(['LSOA'],as_index=False).agg({\n",
    "        'LSOA_name':'max',\n",
    "        'ward_name':'max',\n",
    "        'newGLD': lambda x: (x==False).sum(),\n",
    "        'geometry_home':'max',\n",
    "        'lat_long':'max',\n",
    "        'Bradford_YN':'sum',\n",
    "        'EntitlementFlag':'sum',\n",
    "        'FreeSchoolMeal':'sum',\n",
    "        'SENDFlag': lambda x: (x==True).sum(),\n",
    "        'ever_NEET':'sum',\n",
    "        'Persistent_NEET':'sum',\n",
    "        'language':mode,\n",
    "        'InCare': lambda x: (x==True).sum(),\n",
    "        'person_id':'count'}) \n",
    "GLD_LSOA_format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde1d40-b207-4f60-8363-ed44bc9e5f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lenNotBRADFORD = GLD_LSOA_format.query('Bradford_YN==0')\n",
    "lenNotBRADFORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6def672-ccef-448c-a896-58abcecc53af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lenBRADFORD = GLD_LSOA_format.query('Bradford_YN>=1')\n",
    "lenBRADFORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059734c-070c-4ec6-86ff-d76ac3cb1049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GLD_LSOA_format = GLD_LSOA_format.dropna()\n",
    "totalBradfordPeople = GLD_LSOA_format.Bradford_YN.sum()\n",
    "print(\"totalBradfordPeople\",totalBradfordPeople)\n",
    "totalGLDFailBradford = GLD_LSOA_format.newGLD.sum()\n",
    "print(\"totalGLDFailBradford\",totalGLDFailBradford)\n",
    "totalPersonID = GLD_LSOA_format.person_id.sum()\n",
    "print(\"totalPersonID\",totalPersonID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f21526-9838-4612-a532-46caecafc8c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Count of People 7940 of which 6038 where from Bradford (76%) of which 5105 (64.29%) have failed GLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7e1ab-fd6d-432e-ae7f-090e39f9c3f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "LLD = DFafterMerge.groupby(['LSOA','Gender'], as_index=False).agg({\n",
    "    'person_id':'count',\n",
    "    'newGLD': lambda x: (x==False).sum(),\n",
    "    'ever_NEET':'sum',\n",
    "    'Persistent_NEET':'sum',\n",
    "    'language':mode,\n",
    "    'InCare': lambda x: (x==True).sum(),\n",
    "     'ward_name':'max'})\n",
    "    \n",
    "LLD = LLD.dropna()\n",
    "LLGDraph = LLD.reset_index().sort_values(['newGLD','LSOA'], ascending=False ).query('newGLD>=1').head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd22f82-cee5-4ba4-bc21-beb24110b583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLGDraphIndex = LLGDraph.set_index(['ward_name','Gender'])\n",
    "LLGDraphIndex = LLGDraphIndex.drop(['index','LSOA'],axis=1)\n",
    "LLGDraphIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd203a59-7944-40cb-8036-e49d759f2447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LLGDraphIndex = LLGDraphIndex.drop(['LSOA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85c506-fe2b-447e-8886-82ec8f377760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "LLGDraphIndexFemale = LLGDraphIndex.query(\"Gender.str.contains('F')\")\n",
    "LLGDraphIndexMale = LLGDraphIndex.query(\"Gender.str.contains('M')\")\n",
    "# print(LLGDraphIndexFemale)\n",
    "# print(LLGDraphIndexMale)\n",
    "\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(24,12))\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "LLGDraphIndexFemale.plot(kind='bar',ax=ax1)\n",
    "ax1.set_ylabel('count of GLD non attainment based out of Bradford LSOA ')\n",
    "\n",
    "for bar in ax1.patches:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    ax1.set_title(\"Top 10 Wards: GLD Failure Counts Gender wise\")\n",
    "    \n",
    "\n",
    "LLGDraphIndexMale.plot(kind='bar', ax=ax2)\n",
    "ax2.set_ylabel('count of GLD non attainment based out of Bradford LSOA ')\n",
    "for bar in ax2.patches:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width() / 2.0, height, f' {height:.2f}', fontsize=10,\n",
    "            ha='center')\n",
    "    ax2.set_title(\"Top 10 Wards: GLD Failure Counts Gender wise\")\n",
    "    \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898189e6-48a3-4f81-84af-221c8edbb2bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 117/141 82% female and 224/279 80% male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70fae42-86fb-4d4a-a326-aaee147cbe78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLD_LSOA_format['CountofPeople'] = GLD_LSOA_format['person_id']\n",
    "GLD_LSOA_format['CountofPeopleFailed'] = GLD_LSOA_format['newGLD']\n",
    "GLD_LSOA_format = GLD_LSOA_format.dropna()\n",
    "GLD_LSOA_format.sort_values(['newGLD','LSOA'], ascending=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae75fc-15cf-4864-97a5-aee35a802038",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GeoSpacial Analysis using Choropleth\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Plotting the LSOA with covariates details such as Language, FreeSchoolMeal, SENDFlag etc\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f861af5-8c82-4926-ab85-34d88138ab38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip install geopandas\n",
    "#! pip install cartopy\n",
    "#! pip install contextily\n",
    "#! pip install folium\n",
    "#! pip install geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d085aea-8e85-429c-8195-ee0cb2f3a376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import cartopy as ccrs\n",
    "import contextily as cx\n",
    "import folium\n",
    "import geojson\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6b6e3-baa3-4c28-9053-8c4d935b8a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bradford = folium.Map(tiles=\"CartoDB positron\", location=(53.8313, -1.8431), zoom_start=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680335a-76ae-4ade-ba9b-028cf58db9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLD_LSOA_format['geometry'] = gpd.GeoSeries.from_wkt(GLD_LSOA_format['geometry_home'], crs=4258)\n",
    "gdf_GLD_by_lsoa = gpd.GeoDataFrame(GLD_LSOA_format, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cec9c4-94bf-4052-8154-f86f85f0ec6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " bradfordChoropleth = folium.Choropleth(\n",
    "    geo_data = gdf_GLD_by_lsoa,\n",
    "    data = gdf_GLD_by_lsoa,\n",
    "    columns= ['LSOA','CountofPeople','CountofPeopleFailed','ever_NEET','SENDFlag','FreeSchoolMeal','language','InCare'],\n",
    "    key_on = \"feature.properties.LSOA\",\n",
    "    fill_color=\"YlOrRd\",\n",
    "    fill_opacity=\"0.8\",\n",
    "    line_opacity=\"0.5\",\n",
    "    bins=[0,10,20,30,60,80,100,200],\n",
    "    legend_name=\"Count of People GLD non Attainment, SEND status and Free Meal in Bradford Area\",\n",
    "     tooltip='CountofPeople'\n",
    ").add_to(bradford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21258a-2af8-4661-80ba-7b3a11d58113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bradfordChoropleth.geojson.add_child(folium.features.GeoJsonTooltip(['ward_name', 'CountofPeople','CountofPeopleFailed','ever_NEET','SENDFlag','FreeSchoolMeal','language','InCare'], aliases=['Post Code: ','#of People: ', 'GLD Failed','Ever NEET','SEN','Free School Meal', 'First Language Code', 'In Care']))    \n",
    "folium.LayerControl().add_to(bradford)\n",
    "bradford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7052a6b-cc49-435c-a616-b9ca2f2c06eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(DFafterMerge.ever_NEET.sum())\n",
    "print(len(DFafterMerge.ever_NEET))\n",
    "\n",
    "\n",
    "# model_covariates_flag = sm.formula.glm(\"ever_NEET ~ newGLD+SENDFlag)\",\n",
    "#                        family=sm.families.Binomial(), data=DFafterMerge).fit()\n",
    "\n",
    "model_covariates_flag = sm.formula.glm(\"ever_NEET~ C(newGLD, Treatment(reference=True))\",\n",
    "                       family=sm.families.Binomial(), data=DFafterMerge).fit()\n",
    "\n",
    "    \n",
    "print(model_covariates_flag.summary())\n",
    "predictionsCovaritesFlag=model_covariates_flag.predict()\n",
    "\n",
    "# print(np.unique(predictionsCovaritesFlag))\n",
    "\n",
    "unique, counts = np.unique(predictionsCovaritesFlag, return_counts=True)\n",
    "\n",
    "# print(np.asarray((unique, counts)).T)\n",
    "\n",
    "uniqueT, countsT = np.unique(modelDF['ever_NEET'], return_counts=True)\n",
    "\n",
    "# print(np.asarray((uniqueT, countsT)).T)\n",
    "\n",
    "predictions_CovaritesFlag = [1 if x < 0.3 else 0 for x in predictionsCovaritesFlag]\n",
    "# print(model_covariates_flag.params.Intercept)\n",
    "odds_ratio_covariatesFlag=np.exp(model_covariates_flag.params.Intercept)\n",
    "# print('odds ratio is ',odds_ratio_covariatesFlag)\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'coef': model_covariates_flag.params.values,\n",
    "    'odds ratio': np.exp(model_covariates_flag.params.values),\n",
    "     'p-values': model_covariates_flag.pvalues\n",
    "})\n",
    "print(coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434dede-4e75-407e-9cce-cbbdbca5b3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnf_matrix_CovaritesFlag = confusion_matrix(DFafterMerge[\"ever_NEET\"], \n",
    "#                        predictions_CovaritesFlag)\n",
    "# print(cnf_matrix_CovaritesFlag)\n",
    "\n",
    "# print(classification_report(DFafterMerge[\"ever_NEET\"], \n",
    "#                             predictions_CovaritesFlag, \n",
    "#                             digits = 3))\n",
    "\n",
    "# class_names=[\"0\",\"1\"] # name  of classes\n",
    "# fig, ax = plt.subplots()\n",
    "# tick_marks = np.arange(len(class_names))\n",
    "# plt.xticks(tick_marks, class_names)\n",
    "# plt.yticks(tick_marks, class_names)\n",
    "# # create heatmap\n",
    "# sns.heatmap(pd.DataFrame(cnf_matrix_CovaritesFlag), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "# plt.tight_layout()\n",
    "# plt.title('Confusion matrix', y=1.1)\n",
    "# plt.ylabel('Actual label NEET')\n",
    "# plt.xlabel('Predicted label NEET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64551886-ebba-4edb-97aa-fdc7b191f4a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Structural Equation Model, Simple Regression, XGBClassifiers\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<h3> To understand the predictive power of becoming NEET from other covariates using Structural Equation Modelling \n",
    "Structural equation modeling (SEM) is a multivariate statistical analysis technique that is used to analyze structural relationships between variables under study. This technique uses a combination of factor analysis as well as multiple regression, to analyze the structural relationship between measured variables and latent constructs. This method is preferred by researchers because it estimates the multiple and interrelated dependence in a single analysis.    \n",
    "    \n",
    "    \n",
    "</h3>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae6735-0508-45b0-a716-6c19592be9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install fsspec\n",
    "# !pip install s3fs\n",
    "# !pip install boto\n",
    "# !pip install semopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd1483-c6c1-47b0-8633-68844762e71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto\n",
    "import semopy\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=(SettingWithCopyWarning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee866506-cf38-4019-886d-9c7902ab9e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DFafterMerge.columns\n",
    "DFafterMerge = DFafterMerge.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033de04-7d1b-47a6-a523-94af15e2bdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DFForSemopy = DFafterMerge[['person_id', 'Gender','AcademicYear',  'PSEAS1', 'PSEAS2', 'PSEAS3',\n",
    "       'PSETotal', 'CLLAS1', 'CLLAS2', 'CLLAS3', 'CLLAS4', 'CLLTotal',\n",
    "       'PSRNAS1', 'PSRNAS2', 'PSRNAS3', 'PSRNTotal', 'RKUW', 'RIPD', 'RICD',\n",
    "       'EYFSPTotal','ever_NEET', 'Persistent_NEET', 'Total_neet_months',\n",
    "       'total_number_of_observations', 'percentage_time_neet',\n",
    "       'NumberOfMonthsUnknown', 'newGLD', 'AcademicBegin', 'AcademicEnd',\n",
    "       'FreeSchoolMeal',\n",
    "       'LDDFlag', 'SENDFlag', 'language', 'InCare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c8b1f-40fa-49ff-b8e3-bd029dfb3804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DFForSemopy['language']= DFForSemopy.language.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3e187-0708-4638-ad3e-176181eacaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DFForSemopy[\"LDDFlag\"] = DFForSemopy['LDDFlag'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "DFForSemopy[\"Persistent_NEET\"] = DFForSemopy['Persistent_NEET'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "DFForSemopy[\"newGLD\"] = DFForSemopy['newGLD'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "DFForSemopy[\"FreeSchoolMeal\"] = DFForSemopy['FreeSchoolMeal'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "DFForSemopy[\"SENDFlag\"] = DFForSemopy['SENDFlag'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "DFForSemopy[\"InCare\"] = DFForSemopy['InCare'].apply(lambda set_: 1 if (set_)== True else 0)\n",
    "\n",
    "XGBoostBefore = DFForSemopy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "Gender_encoded_data = encoder.fit_transform(DFForSemopy[['Gender']].to_numpy())\n",
    "Gender_encoded_df = pd.DataFrame(Gender_encoded_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "language_encoded_data = encoder.fit_transform(DFForSemopy[['language']].to_numpy())\n",
    "language_encoded_df = pd.DataFrame(language_encoded_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "DFForSemopyNew = pd.concat([DFForSemopy, Gender_encoded_df, language_encoded_df], axis=1)\n",
    "DFForSemopyNew = DFForSemopyNew.drop(['Gender','language','AcademicYear'], axis=1)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# DFForSemopyNew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb875cde-6fe5-44cb-b1c4-26acd67cf6f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Linear Regression using statsmodels.api.OLS.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>This code iterates through each domain in GLD, creating a separate linear regression model using statsmodels.api.OLS.\n",
    "The summary output provides model statistics and individual feature coefficients for interpretation.\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2173fd-23ea-437e-a919-16beff3e4a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define target variable\n",
    "outcome_var = \"ever_NEET\"\n",
    "\n",
    "\n",
    "domains = 'newGLD','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RIPD','RICD','EYFSPTotal','PSETotal','CLLTotal' \n",
    "all_r_squared = []\n",
    "all_adjusted_r_squared = []\n",
    "all_rmse = []\n",
    "all_num_features = []\n",
    "\n",
    "all_coefficients = []\n",
    "all_std_errors = []\n",
    "all_p_values = []\n",
    "\n",
    "# Loop through each domain\n",
    "for domain in domains:\n",
    "    domain_features = [feature for feature in DFForSemopyNew.columns if feature.startswith(domain)]\n",
    "\n",
    "    print(domain_features)\n",
    "    # Build and fit the model\n",
    "    model = sm.OLS(DFForSemopyNew[outcome_var], DFForSemopyNew[domain_features])\n",
    "    results = model.fit()\n",
    "\n",
    "    # Extract significant features (consider your significance threshold)\n",
    "    pvals = results.pvalues  # Get p-values from the results object\n",
    "    significant_features = pvals[pvals < 0.05].index  # Identify features with p-value < 0.05\n",
    "\n",
    "    # Print summary results\n",
    "    # print(f\"\\n*** {domain.upper()} Domain Regression Results ***\")\n",
    "    # print(results.summary())\n",
    "    \n",
    "    # R-squared\n",
    "    r_squared = results.rsquared\n",
    "    all_r_squared.append(r_squared)\n",
    "    \n",
    "    # Adjusted R-squared\n",
    "    adjusted_r_squared = results.rsquared_adj\n",
    "    all_adjusted_r_squared.append(adjusted_r_squared)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    # 1. Calculate predicted values\n",
    "    predicted_y = results.predict(model.exog)\n",
    "\n",
    "    # 2. Calculate squared residuals\n",
    "    squared_residuals = (predicted_y - model.endog)**2\n",
    "\n",
    "    # 3. Calculate average squared residual (mean)\n",
    "    mean_squared_residual = squared_residuals.mean()\n",
    "\n",
    "    # 4. Take the square root to get RMSE\n",
    "    rmse = np.sqrt(mean_squared_residual)\n",
    "    all_rmse.append(rmse)\n",
    "\n",
    "    # Number of features (excluding intercept)\n",
    "    num_features = len(results.params) - 1  # Remove intercept\n",
    "    all_num_features.append(num_features)\n",
    "    \n",
    "    coefficients = results.params\n",
    "    all_coefficients.append(coefficients)\n",
    "    std_errors = results.bse\n",
    "    all_std_errors.append(std_errors)\n",
    "    p_values = results.pvalues\n",
    "    all_p_values.append(p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc2d30-16b8-4b3e-aa0d-b873ff38b2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Sample data (replace with your actual results)\n",
    "data = {\n",
    "    \"Domain\": domains,\n",
    "    \"R-squared\": all_r_squared,   \n",
    "    \"RMSE\": all_rmse,   \n",
    "    \"Coefficients\":all_coefficients,\n",
    "    \"Standard Errors \": all_std_errors,\n",
    "    \"P-values\":all_p_values\n",
    "}\n",
    "\n",
    "#\"Adjusted R-squared\": all_adjusted_r_squared,\n",
    "#\"Num Features\": all_num_features\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# # Sort by R-squared (descending)\n",
    "#df_sorted = df.sort_values(by=\"Coefficients\", ascending=False)\n",
    "\n",
    "# # Print the table with formatting\n",
    "table = tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(type(table))\n",
    "# import openpyxl\n",
    "# table.to_excel(\"ols_model_output.xlsx\",\n",
    "#               sheet_name='Statistical_significance', index=False) \n",
    "\n",
    "\n",
    "# from openpyxl import Workbook\n",
    "\n",
    "# # Create a workbook and worksheet\n",
    "# wb = Workbook()\n",
    "# ws = wb.active\n",
    "\n",
    "# # Write the table data to the worksheet\n",
    "# ws.append(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\").splitlines())\n",
    "\n",
    "# # Save the workbook\n",
    "# wb.save(\"ols_model_output.xlsx\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db625213-0551-4571-b0d3-b9dc536f45cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# statsmodels.api.OLS for each of the covariant seperately\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>This code iterates through each domain in GLD, creating a separate linear regression model using statsmodels.api.OLS.\n",
    "The summary output provides model statistics and individual feature coefficients for interpretation.\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c22e81-c8a5-4c8f-9fff-33db2c5c7125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define target variable\n",
    "outcome_var = \"ever_NEET\"\n",
    "\n",
    "\n",
    "domains = 'newGLD','PSEAS1','PSEAS2','PSEAS3','CLLAS1','CLLAS2','CLLAS3','CLLAS4','PSRNAS1','PSRNAS2','PSRNAS3','RKUW','RIPD','RICD','EYFSPTotal','PSETotal','CLLTotal' \n",
    "\n",
    "\n",
    "all_coefficients = []\n",
    "all_odds_ratio = []\n",
    "all_p_values = []\n",
    "\n",
    "# Loop through each domain\n",
    "for domain in domains:\n",
    "    domain_features = [feature for feature in DFForSemopyNew.columns if feature.startswith(domain)]\n",
    "    \n",
    "    \n",
    "    formula = f\"ever_NEET ~ {' + '.join(domain_features)} \"  \n",
    "    \n",
    "    #~ C(newGLD+CLLAS1, Treatment(reference=True))\",\n",
    "    \n",
    "    model_covariates_flag = sm.formula.glm(formula,\n",
    "                       family=sm.families.Binomial(), data=DFForSemopyNew).fit()\n",
    "\n",
    "    print(model_covariates_flag.summary())\n",
    "    predictionsCovaritesFlag=model_covariates_flag.predict()\n",
    "\n",
    "    # print(np.unique(predictionsCovaritesFlag))\n",
    "\n",
    "    unique, counts = np.unique(predictionsCovaritesFlag, return_counts=True)\n",
    "\n",
    "    # print(np.asarray((unique, counts)).T)\n",
    "\n",
    "    uniqueT, countsT = np.unique(modelDF['ever_NEET'], return_counts=True)\n",
    "\n",
    "    # print(np.asarray((uniqueT, countsT)).T)\n",
    "\n",
    "    predictions_CovaritesFlag = [1 if x < 0.3 else 0 for x in predictionsCovaritesFlag]\n",
    "    # print(model_covariates_flag.params.Intercept)\n",
    "    odds_ratio_covariatesFlag=np.exp(model_covariates_flag.params.Intercept)\n",
    "    # print('odds ratio is ',odds_ratio_covariatesFlag)\n",
    "    \n",
    "    all_coefficients.append(model_covariates_flag.params.values[1])\n",
    "    all_odds_ratio.append(np.exp(model_covariates_flag.params.values[1]))\n",
    "    all_p_values.append(model_covariates_flag.pvalues[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c11f25-5d89-400b-8132-4f587fa23c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Sample data (replace with your actual results)\n",
    "OLSGLMdata = {\n",
    "    \"Domain\": domains,\n",
    "    \"Coefficients\":all_coefficients,\n",
    "    \"Odds Ratio \": all_odds_ratio,\n",
    "    \"P-values\":all_p_values\n",
    "}\n",
    "\n",
    "#\"Adjusted R-squared\": all_adjusted_r_squared,\n",
    "#\"Num Features\": all_num_features\n",
    "df = pd.DataFrame(OLSGLMdata)\n",
    "\n",
    "# # Sort by R-squared (descending)\n",
    "#df_sorted = df.sort_values(by=\"Coefficients\", ascending=False)\n",
    "\n",
    "\n",
    "# # Print the table with formatting\n",
    "table = tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\")\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "df.to_excel(\"glm_model.xlsx\",\n",
    "              sheet_name='Statistical significance', index=False) \n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4130880-6f95-4194-8279-3388f418bde6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interpreting Structural Equation Model \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Interpreting SEM model results from semopy: Estimate, Std. Err, z-value, and p-value\n",
    "When analyzing a SEM model in semopy, you'll typically encounter four key output values for each parameter:\n",
    "</h2>\n",
    "\n",
    "<li><emphasis>Estimate:</emphasis> This reflects the magnitude and direction of the relationship between two variables in the model. Positive values indicate a positive relationship, while negative values indicate a negative relationship.</li>\n",
    "<li><emphasis>Std. Err:</emphasis> This stands for Standard Error, which represents the estimated variability of the Estimate. A smaller Std. Err. indicates higher precision in the estimate.</li>\n",
    "<li><emphasis>z-value:</emphasis> This is a standardized version of the Estimate, calculated by dividing it by its Std. Err. It reflects the number of standard deviations the Estimate is away from zero.</li>\n",
    "<li><emphasis>p-value:</emphasis> This represents the probability of observing an Estimate as extreme as the one obtained, assuming no true relationship exists between the variables. Smaller p-values indicate stronger evidence against the null hypothesis (no relationship).</li>\n",
    "\n",
    "Here's how to interpret these values:\n",
    "\n",
    "<li><emphasis> Interpreting Estimates:</emphasis>\n",
    "\n",
    "Look for large and consistent Estimates in line with your theoretical expectations.\n",
    "Small and non-significant Estimates (see below) suggest the relationship is weak or not present.</li>\n",
    "    \n",
    "<li><emphasis>Interpreting Std. Err.:</emphasis>\n",
    "\n",
    "Smaller Std. Err. indicates more precise estimates and higher confidence in the Estimate.\n",
    "Larger Std. Err. indicates more uncertainty and less confidence in the Estimate.</li>\n",
    "\n",
    "<li><emphasis>Interpreting z-value:</emphasis>\n",
    "\n",
    "Absolute values greater than 1.96 (95% confidence level) or 2.58 (99% confidence level) are generally considered statistically significant.\n",
    "Higher positive z-values indicate stronger positive relationships.\n",
    "Higher negative z-values indicate stronger negative relationships.</li>\n",
    "    \n",
    "<li><emphasis>Interpreting p-value:</emphasis>\n",
    "\n",
    "Smaller p-values (typically less than 0.05) indicate statistically significant relationships. This means it's unlikely the observed relationship is due to chance.\n",
    "Larger p-values indicate non-significant relationships, suggesting the observed relationship could be due to chance.</li>\n",
    "\n",
    "<li><emphasis>Remember:</emphasis>\n",
    "\n",
    "Consider all four values together for a comprehensive interpretation.\n",
    "Statistical significance alone doesn't guarantee practical importance. Evaluate the magnitude of the Estimate as well.\n",
    "Consider the overall model fit and other model diagnostics to ensure your results are reliable.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b342467-66d7-4fa3-a419-463b0bf03c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_zero_columns = [col for col in DFForSemopyNew.columns if DFForSemopyNew[col].sum() == 0.0]\n",
    "\n",
    "# if all_zero_columns:\n",
    "#     print(\"Columns with all zeros:\", all_zero_columns)\n",
    "# else:\n",
    "#     print(\"No columns with all zeros found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b3c37-8c50-4461-bf14-9465d4f61779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pattern = \"x0_\"\n",
    "\n",
    "# new_col_names = [\n",
    "#     f\"{col} \" if col.startswith(pattern) else col\n",
    "#     for col in DFForSemopyNew.columns\n",
    "# ]\n",
    "# new_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5bd55e-a2f3-4ffc-bbe7-9e825899ad3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea55da7-ec43-4966-8ab6-f0718477b900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_spec = \"\"\"\n",
    "  # measurement model\n",
    "    GLD =~  newGLD + PSEAS1 + PSEAS2 +  PSEAS3+ CLLAS1 + CLLAS2 + CLLAS3 + CLLAS4 + PSRNAS1 + PSRNAS2 + PSRNAS3 + RKUW + RIPD + RICD \n",
    "    Social =~ SENDFlag + FreeSchoolMeal +LDDFlag +x0_F + x0_M\n",
    "    Language =~ x0_BNG+x0_BNGA+x0_BNGS+x0_BSL+x0_CHI+x0_CHIC+x0_ENB+x0_ENG+x0_FRN+x0_HIN+x0_ISL+x0_PNJ+x0_PNJA+x0_PNJG+x0_PNJM+x0_PNJP+x0_POL+x0_RUS+x0_SCB+x0_SWA+x0_SWAA+x0_TAM + x0_TEL+x0_TGL+x0_TGLF +x0_TUR+x0_UKR+x0_URD+x0_missing\n",
    "  # regressions\n",
    "    ever_NEET ~ GLD + Social +Language\n",
    "\"\"\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = semopy.Model(model_spec)\n",
    "\n",
    "# Fit the model using the data\n",
    "model.fit(DFForSemopyNew)\n",
    "\n",
    "dfModelOutput = model.inspect()\n",
    "\n",
    "# print(dfModelOutput)\n",
    "\n",
    "from semopy import gather_statistics\n",
    "gather_stats = gather_statistics(model)\n",
    "stats = semopy.calc_stats(model)\n",
    "g = semopy.semplot(model, \"SemopyModel.png\")\n",
    "# print(stats.T)\n",
    "# print(g)\n",
    "\n",
    "#print(gather_stats)\n",
    "import openpyxl\n",
    "dfModelOutput.to_excel(\"Semopy_model_output.xlsx\",\n",
    "              sheet_name='Statistical significance', index=False) \n",
    "\n",
    "# # Show the results using the inspect method\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295227ce-0892-4d94-844f-c6b438020c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711f9b6-3a61-431e-a901-7c98383d5a3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGBoostClassfier \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>To Plot the feature importance of the domains related to NEET Status\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446a881-5e7f-4ba1-afdd-b0f2ad7f9df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define target variable\n",
    "target_variable = \"ever_NEET\"\n",
    "\n",
    "# 'CLLTotal','PSETotal','PSRNTotal'\n",
    "column_to_include = DFForSemopyNew.drop(['ever_NEET','EYFSPTotal','CLLTotal','PSETotal','PSRNTotal','Total_neet_months','Persistent_NEET','total_number_of_observations',\n",
    " 'percentage_time_neet','NumberOfMonthsUnknown','person_id'],axis=1).columns\n",
    "\n",
    "\n",
    "# List all columns except the one to exclude\n",
    "#columns_except_one = DFForSemopyNew.drop(column_to_exclude, axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    DFForSemopyNew[column_to_include], DFForSemopyNew[target_variable], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define XGBoost model parameters\n",
    "model_params = {\n",
    "    \"objective\": \"reg:logistic\",  # Use \"reg:logistic\" for regression-based prediction\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "}\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBClassifier(**model_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict_proba(X_test)[:, 1]  # Get probability of becoming NEET\n",
    "\n",
    "# Evaluate model performance (e.g., accuracy, AUC-ROC)\n",
    "# Consider using libraries like `sklearn.metrics` for evaluation\n",
    "\n",
    "# Analyze feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "# Visualize or interpret feature importance\n",
    "\n",
    "# Draw conclusions and discuss limitations\n",
    "\n",
    "# Optional: Save the model for future use\n",
    "#model.save_model(\"model.xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c7df2-15a4-4da7-9ffd-9c61ca04f2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plotDF = plot_importance(model, max_num_features=20)  # Show top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778ec20-683d-43ae-9e1f-5527dc7ed96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define target variable\n",
    "target_variable = \"ever_NEET\"\n",
    "\n",
    "\n",
    "column_to_exclude = XGBoostBefore.drop(['ever_NEET','EYFSPTotal','CLLTotal','PSETotal','PSRNTotal','Total_neet_months','Persistent_NEET','total_number_of_observations',\n",
    " 'percentage_time_neet','NumberOfMonthsUnknown','person_id','Gender','AcademicYear','AcademicBegin','AcademicEnd','FreeSchoolMeal','LDDFlag','SENDFlag','newGLD','language','InCare'],axis=1).columns\n",
    "\n",
    "column_to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bef4b6-5551-486b-9b6f-af7299c99ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List all columns except the one to exclude\n",
    "#columns_except_one = DFForSemopyNew.drop(column_to_exclude, axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    DFForSemopyNew[column_to_exclude], DFForSemopyNew[target_variable], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define XGBoost model parameters\n",
    "model_params = {\n",
    "    \"objective\": \"reg:logistic\",  # Use \"reg:logistic\" for regression-based prediction\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "}\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBClassifier(**model_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict_proba(X_test)[:, 1]  # Get probability of becoming NEET\n",
    "\n",
    "# Evaluate model performance (e.g., accuracy, AUC-ROC)\n",
    "# Consider using libraries like `sklearn.metrics` for evaluation\n",
    "\n",
    "# Analyze feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "# Visualize or interpret feature importance\n",
    "\n",
    "# Draw conclusions and discuss limitations\n",
    "\n",
    "# Optional: Save the model for future use\n",
    "#model.save_model(\"model.xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ea349-dc99-40c1-b3f0-0849fc0e3b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plotDF = plot_importance(model, max_num_features=20)  # Show top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88bceb7-43d5-4bdb-9660-9baf8a181ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install econml \n",
    "DFForSemopyNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc61e2-11d4-43c8-9dc4-a7348fa387fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psmpy\n",
    "import seaborn as sns\n",
    "from psmpy import PsmPy\n",
    "from psmpy.functions import cohenD\n",
    "from psmpy.plotting import *\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,8)}, font_scale = 1.3)\n",
    "# Define the treatment, outcome, and covariates\n",
    "data1 = DFForSemopyNew.drop(['EYFSPTotal','CLLTotal','PSETotal','PSRNTotal','Total_neet_months','Persistent_NEET','total_number_of_observations','percentage_time_neet','NumberOfMonthsUnknown','AcademicBegin','AcademicEnd','LDDFlag','newGLD','InCare'],axis=1)\n",
    "data = data1[['person_id','ever_NEET','PSEAS1', 'PSEAS2', 'PSEAS3', 'CLLAS1', 'CLLAS2', 'CLLAS3', 'CLLAS4','PSRNAS1', 'PSRNAS2', 'PSRNAS3', 'RKUW', 'RIPD', 'RICD','SENDFlag', 'FreeSchoolMeal']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8292eb-9254-438b-abb2-559d59f4ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your data\n",
    "# data = DFForSemopyNew[column_to_exclude]\n",
    "outcome = 'ever_NEET'\n",
    "indx='person_id'\n",
    "treatments = ['PSEAS1', 'PSEAS2', 'PSEAS3', 'CLLAS1', 'CLLAS2', 'CLLAS3', 'CLLAS4','PSRNAS1', 'PSRNAS2', 'PSRNAS3', 'RKUW', 'RIPD', 'RICD']\n",
    "covariates = ['SENDFlag', 'FreeSchoolMeal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7143d0e-e1ba-419d-869c-55cbd7d44efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44ac7b-458d-4ea8-9d26-7e4c2874c374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psm = PsmPy(data, treatment=treatments, indx=indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0026e22-8ff9-43b7-b8f6-d773def02b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433d637-9478-4c9d-9aaa-fa50eeeec7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Split the data into treated and control groups\n",
    "# treated = data[data[treatment] == 1]\n",
    "# control = data[data[treatment] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a79416-35d5-4fb0-be2a-c056a2dd2996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psm.logistic_ps(balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b877b4-409f-438b-9b84-a3d3ab7776d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate propensity scores\n",
    "propensity_model = DrWarmStartCV(cv=3, n_jobs=-1)\n",
    "propensity_model.fit(data[covariates], data[treatment])\n",
    "propensity_scores = propensity_model.score(data[covariates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552ecba-8340-42c3-8dd9-66e577d13c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match treated and control units\n",
    "matched_data = intersect_weights(treated, control, propensity_scores)\n",
    "\n",
    "# Estimate the treatment effect\n",
    "model = sm.OLS(matched_data[outcome] ~ matched_data[treatment], data=matched_data).fit()\n",
    "treatment_effect = model.params[treatment]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
